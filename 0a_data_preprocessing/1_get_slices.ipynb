{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to extract slices from hdf5 data files\n",
    "\n",
    "April 7, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "import glob\n",
    "import argparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### Location of hdf5 files\n",
    "data_dir='/global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/'\n",
    "### Extract list of hdf5 files\n",
    "f_list=glob.glob(data_dir+'*.hdf5')\n",
    "len(f_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys ['full', 'namePar', 'physPar', 'redshifts', 'unitPar']\n",
      "Size of full array 512\n",
      "Size of each element (512, 512, 4)\n",
      "512\n",
      "namePar\n",
      "[b'Omega_m', b'sigma_8', b'N_spec', b'H_0']\n",
      "physPar\n",
      "[0.32781, 0.849941, 0.938285, 57.778255]\n",
      "redshifts\n",
      "[0.0, 0.5, 1.5, 3.0]\n",
      "unitPar\n",
      "[0.3089974, 0.2080883, -0.0753999, -0.5819879]\n"
     ]
    }
   ],
   "source": [
    "### Explore the hdf5 file\n",
    "def f_explore_file(fname):\n",
    "    '''\n",
    "    Explore the structure of the hdf5 file\n",
    "    The Keys are : ['full', 'namePar', 'physPar', 'redshifts', 'unitPar']\n",
    "    'full' has many elements. Each is a numpy array with shape (512,512,4) \n",
    "    The last index 4 corresponds to red-shift. Eg. 0, 0.5, 1.5, 3.0\n",
    "    '''\n",
    "    dta=h5py.File(fname,'r') \n",
    "    print('Keys',[i for i in dta])\n",
    "    print('Size of full array',len(dta['full']))\n",
    "    print('Size of each element',dta['full'][0].shape)\n",
    "    print(len(dta['full']))\n",
    "    for key in ['namePar', 'physPar', 'redshifts', 'unitPar']:\n",
    "        print(key)\n",
    "        print([i for i in dta[key]])\n",
    "    \n",
    "f_explore_file(f_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_get_slices_all_axes(f_list,splice_interval=8):\n",
    "    '''\n",
    "    Get 2D slices of 512^3 images along all 3 axes\n",
    "    splice_interval is the spacing between layers \n",
    "    '''\n",
    "    \n",
    "    slices = []\n",
    "    img_dim = 128\n",
    "    perside = 512//img_dim\n",
    "    \n",
    "    for fname in f_list:\n",
    "        with h5py.File(fname, 'r') as inputdata:\n",
    "            for i1 in range(perside):\n",
    "                for i2 in range(perside):\n",
    "                    # Select slices along planes : xy,yz, zx, for redshift=0 \n",
    "                    # (128 * 128 images from 512 x 512 images-> 16 images)\n",
    "                    ## yz axis: \n",
    "                    data = inputdata['full'][::splice_interval, i1*img_dim:(i1+1)*img_dim, i2*img_dim:(i2+1)*img_dim, 0]\n",
    "                    data2=np.transpose(data,(0,1,2)) ### Transpose to get array in the form (samples,128,128)\n",
    "                    np.random.shuffle(data2) ### Shuffle samples (along first axis)\n",
    "                    slices.append(np.expand_dims(data2, axis=-1))\n",
    "\n",
    "                    ## xy axis: \n",
    "                    data = inputdata['full'][i1*img_dim:(i1+1)*img_dim,i2*img_dim:(i2+1)*img_dim,::splice_interval,0]\n",
    "                    data2=np.transpose(data,(2,0,1)) ### Transpose to get array in the form (samples,128,128)\n",
    "                    np.random.shuffle(data2) ### Shuffle samples (along first axis)\n",
    "                    slices.append(np.expand_dims(data2, axis=-1))      \n",
    "\n",
    "                    ## xz axis: \n",
    "                    data = inputdata['full'][i1*img_dim:(i1+1)*img_dim,::splice_interval,i2*img_dim:(i2+1)*img_dim,0]\n",
    "                    data2=np.transpose(data,(1,0,2))  ### Transpose to get array in the form (samples,128,128)\n",
    "                    np.random.shuffle(data2) ### Shuffle samples (along first axis)\n",
    "                    slices.append(np.expand_dims(data2, axis=-1))\n",
    "\n",
    "        print('Sliced %s'%fname)\n",
    "    slices = np.concatenate(slices)\n",
    "    print(slices.shape)\n",
    "    \n",
    "    return slices\n",
    "\n",
    "\n",
    "# slices=f_get_slices_all_axes(f_list[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.vsplit(data,data.shape[0])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a1313490.hdf5\n",
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a12530935.hdf5\n",
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a7894967.hdf5\n",
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a8186150.hdf5\n",
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a3610230.hdf5\n",
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a12980342.hdf5\n",
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a16082405.hdf5\n",
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a6202700.hdf5\n",
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a2025313.hdf5\n",
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a1534972.hdf5\n",
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a6424401.hdf5\n",
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a13573022.hdf5\n",
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a5265478.hdf5\n",
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a5865187.hdf5\n",
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a13316018.hdf5\n",
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a16229539.hdf5\n",
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a12957905.hdf5\n",
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a12635142.hdf5\n",
      "Sliced /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/univ_ics_2019-03_a12632823.hdf5\n",
      "(116736, 128, 128, 1)\n",
      "Time taken 71.75737071037292\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "slices=f_get_slices_all_axes(f_list,4)\n",
    "t2=time.time()\n",
    "print('Time taken',t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving file /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/large_dataset_train.npy\n",
      "shape=(105062, 128, 128, 1)\n",
      "Saving file /global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/large_dataset_val.npy\n",
      "shape=(11674, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "### Save data to files\n",
    "\n",
    "### Location to store the .npy files generated by this code\n",
    "dest_dir='/global/project/projectdirs/dasrepo/vpa/cosmogan/data/raw_data/'\n",
    "file_prefix='large_dataset'\n",
    "\n",
    "train_index=np.int(0.90*len(slices))\n",
    "train = slices[:train_index]\n",
    "val = slices[train_index:]\n",
    "\n",
    "train_fname = dest_dir+file_prefix+'_train.npy'\n",
    "print('Saving file %s'%train_fname)\n",
    "print('shape='+str(train.shape))\n",
    "np.save(train_fname, train)\n",
    "\n",
    "val_fname = dest_dir+file_prefix+'_val.npy'\n",
    "print('Saving file %s'%val_fname)\n",
    "print('shape='+str(val.shape))\n",
    "np.save(val_fname, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_slice_universes.py  1_get_slices.ipynb  slice_universes.py\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_py3",
   "language": "python",
   "name": "v_jpt_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

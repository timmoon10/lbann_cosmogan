{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from output files\n",
    "### Analyze the output from a single LBANN run\n",
    "March 9, 2020\n",
    "\n",
    "April 6, 2020 : Major edit to store files in order of epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import subprocess as sp\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import time\n",
    "from scipy import fftpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook modules_image_analysis.ipynb to script\n",
      "[NbConvertApp] Writing 8912 bytes to modules_image_analysis.py\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/LBANN/lbann_cosmogan/3_analysis/')\n",
    "from modules_image_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transformation functions for image pixel values\n",
    "def f_transform(x):\n",
    "    return 2.*x/(x + 4. + 1e-5) - 1.\n",
    "\n",
    "def f_invtransform(s):\n",
    "    return 4.*(1. + s)/(1. - s + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_get_samples(df,key):\n",
    "    '''\n",
    "    Extract array of samples from the DataFrame with images\n",
    "    Images are of two types:\n",
    "    1. *_gen have shape (64,1,128,128)\n",
    "    2. *_input have shape (64,16384)\n",
    "    '''\n",
    "    \n",
    "    keys=['train_gen','train_input','val_gen','val_input']\n",
    "    assert key in keys,\"Given key %s is not the the list of keys %s\"%(key,keys)\n",
    "    \n",
    "    lst=df[df.type==key]['image'].values\n",
    "    \n",
    "    if key.endswith('input'):\n",
    "        size=np.int(np.sqrt(lst[0].shape[-1])) ### Extract size of images (=128)\n",
    "        samples=np.array([ii[0,:].reshape(size,size) for ii in lst])\n",
    "    else : \n",
    "        samples=np.array([ii[0,0,:,:] for ii in lst])\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract image data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/20200409_061557_exagan_no_mcr/dump_outs/\n"
     ]
    }
   ],
   "source": [
    "fldr_name='20200316_112134_exagan'\n",
    "fldr_name='20200406_080207_exagan_with_mcr'\n",
    "fldr_name='20200407_093719_exagan_no_mcr'\n",
    "\n",
    "fldr_name='20200409_061557_exagan_no_mcr'\n",
    "\n",
    "### Code for set of runs\n",
    "# f_list=['20200401_125919_exagan_0.1_1','20200401_130321_exagan_0.1_4',\n",
    "#         '20200401_130907_exagan_0.3_1','20200401_130646_exagan_0.3_4']\n",
    "# fldr_name=f_list[0]\n",
    "\n",
    "main_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/{0}/dump_outs/'.format(fldr_name)\n",
    "print(main_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_gen 169\n",
      "train_input 169\n",
      "val_gen 19\n",
      "val_input 19\n",
      "Sorting done\n",
      "Extraction done\n",
      "Time for Sorting 1.6363329887390137\n",
      "Time for Reading images 8.956344366073608\n",
      "(376, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Get images files and .npy arrays for each image in dump_outs folder\n",
    "files_dict={}\n",
    "keys=['train_gen','train_input','val_gen','val_input']\n",
    "file_strg_lst=['model0-training*-gen_img*-output0.npy','model0-training*-inp_img*-output0.npy','model0-validation*-gen_img*-output0.npy','model0-validation*-inp_img*-output0.npy']\n",
    "for key,file_strg in zip(keys,file_strg_lst):\n",
    "    files_dict[key]=np.array(glob.glob(main_dir+file_strg))\n",
    "    if files_dict[key].shape[0]>1000 : \n",
    "        print('Warning the number of files is very large. Possibility of memory overload')\n",
    "\n",
    "df_files=pd.DataFrame([])\n",
    "dict1={}\n",
    "t1=time.time()\n",
    "### First get sorted Dataframe with file names\n",
    "for key in keys: \n",
    "    files_arr=files_dict[key]  # Get array of files\n",
    "    print(key,len(files_arr))\n",
    "    for fname in files_arr:\n",
    "        ### Extract the Epoch number and step number from the file name\n",
    "        dict1['type']=key\n",
    "        dict1['epoch']=np.int32(fname.split('epoch')[-1].split('-')[0])\n",
    "        dict1['step']=np.int64(fname.split('step')[-1].split('-')[0])\n",
    "        dict1['fname']=fname\n",
    "        \n",
    "        df_files=df_files.append(dict1,ignore_index=True)\n",
    "## Sort values\n",
    "df_files=df_files.sort_values(by=['type','epoch','step']).reset_index(drop=True)\n",
    "# df_files\n",
    "print(\"Sorting done\")\n",
    "\n",
    "t2=time.time()\n",
    "### Then read images one by one into a numpy array and create a new DataFrame\n",
    "sorted_fnames=df_files.fname.values\n",
    "### Read images one by one. This is time-consuming.\n",
    "### Deliberately kept as list because some of the input arrays have different dimensions, causing creation of array of arrays in some cases\n",
    "images=[np.load(fname) for fname in sorted_fnames]  \n",
    "\n",
    "##### Create new Dataframe with sorted images\n",
    "df_full=pd.DataFrame([])\n",
    "df_full['image']=images\n",
    "t3=time.time()\n",
    "for col in ['epoch','step','type','fname']: df_full[col]=df_files[col].values\n",
    "print(\"Extraction done\")\n",
    "\n",
    "print(\"Time for Sorting\",t2-t1)\n",
    "print(\"Time for Reading images\",t3-t2)\n",
    "\n",
    "\n",
    "# ## Slice DataFrame before getting samples. Get 1 images per epochs (choose the last step)\n",
    "# df=pd.DataFrame([])\n",
    "# epochs=np.unique(df_full.epoch.values)\n",
    "# for epoch in epochs:\n",
    "#     df2=df_full[df_full.epoch==epoch]\n",
    "#     df=df.append(df2.iloc[-1])  ### Extract the last step in each epoch\n",
    "df=df_full.copy()\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_files.head(30)\n",
    "# df_files[df_files.type=='val_gen']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169, 128, 128)\n",
      "(19, 128, 128)\n",
      "(169, 128, 128)\n",
      "(19, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "### Available options : keys=['train_gen','train_input','val_gen','val_input']\n",
    "samples1=f_get_samples(df,'train_input')\n",
    "print(samples1.shape)\n",
    "samples2=f_get_samples(df,'val_gen')\n",
    "print(samples2.shape)\n",
    "\n",
    "samples3=f_get_samples(df,'train_gen')\n",
    "print(samples3.shape)\n",
    "samples4=f_get_samples(df,'val_input')\n",
    "print(samples4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539341c6e8474b428b0820332648e0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085fae4a7a244d28a6702323a8326b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53fea7e9f11048aeaa0c82506b09470b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/LBANN/lbann_cosmogan/3_analysis/modules_image_analysis.py:128: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  chi=np.sum(np.divide(np.power(hist1 - hist2, 2.0), hist1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_pixel_intensity(samples1,normalize=False)\n",
    "f_pixel_intensity(samples3,normalize=False)\n",
    "\n",
    "f_compare_pixel_intensity(samples4,samples2,label1='input',label2='generated',normalize=True)\n",
    "# plt.savefig('comparison_intensity.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14561f882c584bdbb28aa88aaa11f32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d953e64f75cc4406b463a0b4d5298ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([311275,      6,      2,      2,      3,      0,      1,      0,\n",
       "            1,      0,      1,      0,      0,      2,      1,      0,\n",
       "            0,      1,      0,      0,      0,      0,      0,      0,\n",
       "            1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_pixel_intensity(f_invtransform(samples1),normalize=False)\n",
    "# f_pixel_intensity(f_invtransform(samples2),normalize=True)\n",
    "# f_pixel_intensity(f_invtransform(samples2[:30]),normalize=False)\n",
    "f_pixel_intensity(f_invtransform(samples2),normalize=False)\n",
    "# f_pixel_intensity(f_invtransform(samples2[60:90]),normalize=False)\n",
    "# f_pixel_intensity(f_invtransform(samples2[90:]),normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669445487b4f4ac6b43a08861eba8ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/LBANN/lbann_cosmogan/3_analysis/modules_image_analysis.py:128: RuntimeWarning: invalid value encountered in true_divide\n",
      "  chi=np.sum(np.divide(np.power(hist1 - hist2, 2.0), hist1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_compare_pixel_intensity(f_invtransform(samples4),f_invtransform(samples2[6:13]),label1='input',label2='generated',normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1992223a40964d46a1e49d04d247ba4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def f_plot_intensity_grid(arr,cols=5):\n",
    "    \n",
    "    size=arr.shape[0]\n",
    "    assert cols<=size, \"cols %s greater than array size %s\"%(cols,size)\n",
    "    \n",
    "    num=arr.shape[0]\n",
    "    rows=int(num/cols)+1\n",
    "#     print(\"Plotting %s images\" %(rows*cols))\n",
    "    fig,axarr=plt.subplots(rows,cols,figsize=(8,4),constrained_layout=True)\n",
    "    for i in range(rows*cols):\n",
    "        row,col=int(i/cols),i%cols\n",
    "        ### Get histogram\n",
    "        try: \n",
    "            img_arr=arr[i]\n",
    "            norm=False\n",
    "            hist, bin_edges = np.histogram(img_arr.flatten(), bins=25, density=norm)\n",
    "            centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "            axarr[row,col].errorbar(centers,hist,fmt='o-')\n",
    "#         fig.subplots_adjust(left=0.01,bottom=0.01,right=0.1,top=0.1,wspace=0.001,hspace=0.0001)\n",
    "        except: \n",
    "            pass\n",
    "\n",
    "# f_plot_intensity_grid(samples2[40:80][::5],cols=6)\n",
    "f_plot_intensity_grid(f_invtransform(samples2),cols=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_pixel_intensity(f_invtransform(samples3[400:]),normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_compute_spectrum(samples1)\n",
    "# f_compute_spectrum(f_invtransform(samples2[51:80]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start,end=51,80\n",
    "f_compare_spectrum(samples4,samples2[51:80],label1='input',label2='generated')\n",
    "f_compare_spectrum(f_invtransform(samples4),f_invtransform(samples2[51:80]),label1='input',label2='generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_compare_spectrum(samples4,samples2[90:140],label1='input',label2='generated')\n",
    "f_compare_spectrum(f_invtransform(samples4),f_invtransform(samples2[90:140]),label1='input',label2='generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the region without very high pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e86b359734e41b7ae8f75af61e560e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f_plot_max_values(samples,cutoff=0.994):\n",
    "    '''\n",
    "    Make a plot of max values of images of a given set of sample images\n",
    "    cutoff used to discard high values\n",
    "    '''\n",
    "    ### Get max pixel values of images\n",
    "    max_values=np.array([np.max(i) for i in samples])\n",
    "    ### Less than cutoff\n",
    "    lesser_idx=np.where(max_values<cutoff)[0]\n",
    "    higher_idx=np.where(max_values>=cutoff)[0]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(lesser_idx,max_values[lesser_idx],linestyle='',marker='*',color='r')\n",
    "    plt.plot(higher_idx,max_values[higher_idx],linestyle='',marker='D',color='b')\n",
    "\n",
    "    plt.axhline(y=cutoff,linestyle='--',color='k')\n",
    "    plt.ylim(0.9,1.0)\n",
    "    \n",
    "f_plot_max_values(samples2,0.9945)\n",
    "# f_plot_max_values(samples4,0.992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.001905487804878"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10506/(64.*82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_py3",
   "language": "python",
   "name": "v_jpt_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

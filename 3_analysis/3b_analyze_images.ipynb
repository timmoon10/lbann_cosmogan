{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from output files\n",
    "### Analyze the output from a single LBANN run\n",
    "March 9, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import subprocess as sp\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import time\n",
    "from scipy import fftpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook modules_image_analysis.ipynb to script\n",
      "[NbConvertApp] Writing 8884 bytes to modules_image_analysis.py\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/LBANN/lbann_cosmogan/3_analysis/')\n",
    "from modules_image_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transformation functions for image pixel values\n",
    "def f_transform(x):\n",
    "    return 2.*x/(x + 4. + 1e-5) - 1.\n",
    "\n",
    "def f_invtransform(s):\n",
    "    return 4.*(1. + s)/(1. - s + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_get_samples(df,key):\n",
    "    '''\n",
    "    Extract array of samples from the DataFrame with images\n",
    "    Images are of two types:\n",
    "    1. *_gen have shape (64,1,128,128)\n",
    "    2. *_input have shape (64,16384)\n",
    "    '''\n",
    "    \n",
    "    keys=['train_gen','train_input','val_gen','val_input']\n",
    "    assert key in keys,\"Given key %s is not the the list of keys %s\"%(key,keys)\n",
    "    \n",
    "    lst=df[df.type==key]['image'].values\n",
    "    \n",
    "    if key.endswith('input'):\n",
    "        size=np.int(np.sqrt(lst[0].shape[-1])) ### Extract size of images (=128)\n",
    "        samples=np.array([ii[0,:].reshape(size,size) for ii in lst])\n",
    "    else : \n",
    "        samples=np.array([ii[0,0,:,:] for ii in lst])\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract image data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/20200406_080207_exagan/dump_outs/\n"
     ]
    }
   ],
   "source": [
    "fldr_name='20200316_112134_exagan'\n",
    "fldr_name='20200331_131011_exagan'\n",
    "fldr_name='20200403_132121_exagan'\n",
    "fldr_name='20200406_080207_exagan'\n",
    "\n",
    "# f_list=['20200401_125919_exagan_0.1_1','20200401_130321_exagan_0.1_4',\n",
    "#         '20200401_130907_exagan_0.3_1','20200401_130646_exagan_0.3_4']\n",
    "# fldr_name=f_list[0]\n",
    "\n",
    "main_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/{0}/dump_outs/'.format(fldr_name)\n",
    "print(main_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning the number of files is very large. Possibility of memory overload\n",
      "Warning the number of files is very large. Possibility of memory overload\n",
      "train_gen 1847\n",
      "train_input 1847\n",
      "val_gen 208\n",
      "val_input 208\n",
      "Sorting done\n",
      "Extraction done\n",
      "152.9934754371643 19.918874740600586\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Get images files and .npy arrays for each image in dump_outs folder\n",
    "files_dict={}\n",
    "keys=['train_gen','train_input','val_gen','val_input']\n",
    "file_strg_lst=['model0-training*-gen_img*-output0.npy','model0-training*-inp_img*-output0.npy','model0-validation*-gen_img*-output0.npy','model0-validation*-inp_img*-output0.npy']\n",
    "for key,file_strg in zip(keys,file_strg_lst):\n",
    "    files_dict[key]=np.array(glob.glob(main_dir+file_strg))\n",
    "    if files_dict[key].shape[0]>1000 : \n",
    "        print('Warning the number of files is very large. Possibility of memory overload')\n",
    "\n",
    "df_files=pd.DataFrame([])\n",
    "dict1={}\n",
    "t1=time.time()\n",
    "### First get sorted Dataframe with file names\n",
    "for key in keys: \n",
    "    files_arr=files_dict[key]  # Get array of files\n",
    "    print(key,len(files_arr))\n",
    "    for fname in files_arr:\n",
    "        ### Extract the Epoch number and step number from the file name\n",
    "        dict1['type']=key\n",
    "        dict1['epoch']=np.int32(fname.split('epoch')[-1].split('-')[0])\n",
    "        dict1['step']=np.int64(fname.split('step')[-1].split('-')[0])\n",
    "        dict1['fname']=fname\n",
    "        \n",
    "        df_files=df_files.append(dict1,ignore_index=True)\n",
    "## Sort values\n",
    "df_files=df_files.sort_values(by=['type','epoch','step']).reset_index(drop=True)\n",
    "# df_files\n",
    "print(\"Sorting done\")\n",
    "t2=time.time()\n",
    "### Then read images one by one into a numpy array and create a new DataFrame\n",
    "sorted_fnames=df_files.fname.values\n",
    "### Read images one by one. This is time-consuming.\n",
    "### Deliberately kept as list because some of the input arrays have different dimensions, causing creation of array of arrays in some cases\n",
    "images=[np.load(fname) for fname in sorted_fnames]  \n",
    "\n",
    "##### Create new Dataframe with sorted images\n",
    "df=pd.DataFrame([])\n",
    "df['image']=images\n",
    "t3=time.time()\n",
    "for col in ['epoch','step','type','fname']: df[col]=df_files[col].values\n",
    "\n",
    "    \n",
    "# df['epoch']=df_files.epoch.values\n",
    "# df['step']=df_files.step.values\n",
    "# df['type']=df_files.type.values\n",
    "# df['image'].values[0].shape\n",
    "print(\"Extraction done\")\n",
    "print(t3-t2,t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_files.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Available options : keys=['train_gen','train_input','val_gen','val_input']\n",
    "samples1=f_get_samples(df,'train_input')\n",
    "print(samples1.shape)\n",
    "samples2=f_get_samples(df,'val_gen')\n",
    "print(samples2.shape)\n",
    "\n",
    "samples3=f_get_samples(df,'train_gen')\n",
    "print(samples3.shape)\n",
    "samples4=f_get_samples(df,'val_input')\n",
    "print(samples4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pixel_intensity(samples1,normalize=False)\n",
    "f_pixel_intensity(samples2,normalize=False)\n",
    "\n",
    "f_compare_pixel_intensity(samples1,samples2,label1='input',label2='generated',normalize=True)\n",
    "# plt.savefig('comparison_intensity.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_plot_intensity_grid(arr,cols=5):\n",
    "    \n",
    "    size=arr.shape[0]\n",
    "    assert cols<=size, \"cols %s greater than array size %s\"%(cols,size)\n",
    "    \n",
    "    num=arr.shape[0]\n",
    "    rows=int(num/cols)+1\n",
    "#     print(\"Plotting %s images\" %(rows*cols))\n",
    "    fig,axarr=plt.subplots(rows,cols,figsize=(12,12),constrained_layout=True)\n",
    "    for i in range(rows*cols):\n",
    "        row,col=int(i/cols),i%cols\n",
    "        ### Get histogram\n",
    "        try: \n",
    "            img_arr=arr[i]\n",
    "            norm=False\n",
    "            hist, bin_edges = np.histogram(img_arr.flatten(), bins=25, density=norm)\n",
    "            centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "            axarr[row,col].errorbar(centers,hist,fmt='o-')\n",
    "#         fig.subplots_adjust(left=0.01,bottom=0.01,right=0.1,top=0.1,wspace=0.001,hspace=0.0001)\n",
    "        except: \n",
    "            pass\n",
    "\n",
    "f_plot_intensity_grid(samples2[20:40],cols=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_pixel_intensity(f_invtransform(samples3[400:]),normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pixel_intensity(f_invtransform(samples1),normalize=False)\n",
    "f_pixel_intensity(f_invtransform(samples2),normalize=True)\n",
    "f_pixel_intensity(f_invtransform(samples2[:30]),normalize=False)\n",
    "f_pixel_intensity(f_invtransform(samples2[30:60]),normalize=False)\n",
    "f_pixel_intensity(f_invtransform(samples2[60:90]),normalize=False)\n",
    "f_pixel_intensity(f_invtransform(samples2[90:]),normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_compare_spectrum(samples1,samples2,label1='input',label2='generated')\n",
    "# ? f_compare_spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect individual sample arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_compute_spectrum(samples1)\n",
    "f_compute_spectrum(samples2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_py3",
   "language": "python",
   "name": "v_jpt_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from output files\n",
    "### Analyze the output from a single LBANN run\n",
    "March 9, 2020 \\\n",
    "April 6, 2020 : Major edit to store files in order of epochs \\\n",
    "April 21, 2020: Major edit, added jupyter widgets to compare pixel intensity plots\n",
    "\n",
    "May 8, 2020: Major edit, using all images for a given batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import subprocess as sp\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import time\n",
    "from scipy import fftpack\n",
    "# from ipywidgets import interact, interact_manual,fixed, SelectMultiple, IntText, IntSlider, FloatSlider,SelectionSlider,BoundedIntText\n",
    "from ipywidgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook modules_image_analysis.ipynb to script\n",
      "[NbConvertApp] Writing 15104 bytes to modules_image_analysis.py\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/LBANN/lbann_cosmogan/3_analysis/')\n",
    "from modules_image_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transformation functions for image pixel values\n",
    "\n",
    "def f_transform_new(x):\n",
    "    if x<=50:\n",
    "        a=0.03; b=-1.0\n",
    "        return a*x+b\n",
    "    elif x>50: \n",
    "        a=0.5/np.log(300)\n",
    "        b=0.5-a*np.log(50)\n",
    "        return a*np.log(x)+b\n",
    "\n",
    "def f_invtransform_new(y):\n",
    "    if y<=0.5:\n",
    "        a=0.03;b=-1.0\n",
    "        return (y-b)/a\n",
    "    elif y>0.5: \n",
    "        a=0.5/np.log(300)\n",
    "        b=0.5-a*np.log(50)\n",
    "        return np.exp((y-b)/a)\n",
    "    \n",
    "    \n",
    "    \n",
    "def f_transform(x):\n",
    "    return np.vectorize(f_transform_new)(x)\n",
    "\n",
    "def f_invtransform(s):\n",
    "    return np.vectorize(f_invtransform_new)(s)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules for Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_get_files_df_sorted():\n",
    "    '''\n",
    "    Module to create Dataframe with filenames for each epoch and step\n",
    "    Sorts by step and epoch\n",
    "    '''\n",
    "    \n",
    "    ## Get images files and .npy arrays for each image in dump_outs folder\n",
    "    t1=time.time()\n",
    "    files_dict={}\n",
    "    keys=['train_gen','train_input','val_gen','val_input']\n",
    "    file_strg_lst=['model0-training*-gen_img*-output0.npy','model0-training*-inp_img*-output0.npy','model0-validation*-gen_img*-output0.npy','model0-validation*-inp_img*-output0.npy']\n",
    "    for key,file_strg in zip(keys,file_strg_lst):\n",
    "        files_dict[key]=np.array(glob.glob(main_dir+file_strg))\n",
    "        if files_dict[key].shape[0]>1000 : \n",
    "            print('Warning the number of files is very large. Possibility of memory overload')\n",
    "\n",
    "    df_files=pd.DataFrame([])\n",
    "    dict1={}\n",
    "    t1=time.time()\n",
    "    ### First get sorted Dataframe with file names\n",
    "    for key in keys: \n",
    "        files_arr=files_dict[key]  # Get array of files\n",
    "        print(key,len(files_arr))\n",
    "        for fname in files_arr:\n",
    "            ### Extract the Epoch number and step number from the file name\n",
    "            dict1['img_type']=key\n",
    "            dict1['epoch']=np.int32(fname.split('epoch')[-1].split('-')[0])\n",
    "            dict1['step']=np.int64(fname.split('step')[-1].split('-')[0])\n",
    "            dict1['fname']=fname\n",
    "\n",
    "            df_files=df_files.append(dict1,ignore_index=True)\n",
    "    ## Sort values\n",
    "    df_files=df_files.sort_values(by=['img_type','epoch','step']).reset_index(drop=True)\n",
    "    # df_files\n",
    "    t2=time.time()\n",
    "    print(\"Time for Sorting\",t2-t1)\n",
    "    \n",
    "    return df_files\n",
    "\n",
    "\n",
    "def f_filter_epoch(df_input,num_sliced=1):\n",
    "    '''\n",
    "    Get just the last few stored step images for each epoch\n",
    "    '''\n",
    "    print('Extracting last %s steps of each epoch'%(num_sliced))\n",
    "    df_output=pd.DataFrame([])\n",
    "    for key in ['train_gen','train_input','val_gen','val_input']: \n",
    "        ### For each type of images, get list of epochs\n",
    "        df1=df_input[df_input.img_type==key]\n",
    "        epochs=np.unique(df1.epoch.values).astype(int)\n",
    "\n",
    "        for epoch in epochs:### Extract the last few steps in each epoch\n",
    "            df2=df1[df1.epoch==epoch]\n",
    "            df_output=df_output.append(df2.iloc[-num_sliced:])  \n",
    "    \n",
    "    return df_output.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def f_get_images_df(df_files):\n",
    "    '''\n",
    "    Read dataframe with file names, read files and create new dataframe with images as numpy arrays\n",
    "    Also computes number of images with intensity beyond a cutoff\n",
    "    '''\n",
    "    \n",
    "    def f_row(df_row):\n",
    "        '''\n",
    "        Extract image\n",
    "        '''\n",
    "        fname,key=df_row.fname,df_row.img_type\n",
    "        a1=np.load(fname)\n",
    "        if key.endswith('input'): \n",
    "            size=np.int(np.sqrt(a1.shape[-1])) ### Extract size of images (=128)\n",
    "            batch_size=a1.shape[0] ### Number of batches\n",
    "            samples=a1.reshape(batch_size,size,size)\n",
    "        elif key.endswith('gen') : samples=a1[:,0,:,:]\n",
    "        else : raise SystemError\n",
    "\n",
    "        return samples\n",
    "    \n",
    "    def f_high_pixel(df_row,cutoff=0.9966):\n",
    "        '''\n",
    "        Get number of images with a pixel about max cut-off value\n",
    "        '''\n",
    "        max_arr=np.amax(df_row.images,axis=(1,2))\n",
    "        num_large=max_arr[max_arr>cutoff].shape[0]\n",
    "\n",
    "        return num_large\n",
    "    \n",
    "    t1=time.time()\n",
    "    ##### Create new Dataframe with sorted images\n",
    "    df=df_files.copy()\n",
    "    df['images']=df.apply(lambda row: f_row(row), axis=1)\n",
    "    t2=time.time()\n",
    "    print(\"Time for Reading images\",t2-t1)\n",
    "    \n",
    "    ### Store the number of images with large pixel value\n",
    "    cutoff=0.9966\n",
    "    df['num_large']=df.apply(lambda row: f_high_pixel(row,cutoff), axis=1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def f_get_samples(df,img_type,start_epoch=0,end_epoch=None):\n",
    "    '''\n",
    "    Module to extract images for a range of epochs given a dataframe\n",
    "    '''\n",
    "    if end_epoch==None: end_epoch=start_epoch+1\n",
    "    \n",
    "    arr=df[(df.epoch>=start_epoch) & (df.epoch<=end_epoch) & (df.img_type==img_type)].images.values\n",
    "    arr=np.vstack(arr)\n",
    "#     print(arr.shape,np.max(arr))    \n",
    "    \n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract image data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/20200516_183817_new_trans_no_mcr/dump_outs/\n"
     ]
    }
   ],
   "source": [
    "fldr_name='20200423_122631_exagan_modified_paddding'\n",
    "fldr_name='20200424_083456_exagan_modified_padding_2'\n",
    "fldr_name='20200506_121613_exagan_200k_samples'\n",
    "fldr_name='20200513_121910_peters_dataset'\n",
    "fldr_name='20200516_183817_new_trans_no_mcr'\n",
    "main_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/{0}/dump_outs/'.format(fldr_name)\n",
    "print(main_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_gen 902\n",
      "train_input 902\n",
      "val_gen 226\n",
      "val_input 226\n",
      "Time for Sorting 7.341293573379517\n",
      "Extracting last 2 steps of each epoch\n",
      "Time for Reading images 57.74587154388428\n",
      "(480, 6)\n"
     ]
    }
   ],
   "source": [
    "### Get dataframe with file names, sorted by epoch and step\n",
    "df_files=f_get_files_df_sorted()\n",
    "\n",
    "### Slice out rows to keep only the last few steps for each epoch.\n",
    "df_files=f_filter_epoch(df_files,num_sliced=2)\n",
    "\n",
    "#############################################################\n",
    "### Read images one by one into a numpy array and create a new DataFrame\n",
    "df=f_get_images_df(df_files)\n",
    "print(df.shape)\n",
    "\n",
    "# ### Filter to keep just one step per epoch\n",
    "# df=f_filter_epoch(df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>fname</th>\n",
       "      <th>img_type</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>1148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>1230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>2378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>2460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>3608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>3690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>4838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>4920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>6068.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>6150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>7298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>7380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>8528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>8610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>9758.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>9840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>10988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>11070.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>12218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>12300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch                                              fname   img_type  \\\n",
       "0     0.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "1     0.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "2     1.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "3     1.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "4     2.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "5     2.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "6     3.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "7     3.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "8     4.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "9     4.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "10    5.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "11    5.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "12    6.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "13    6.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "14    7.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "15    7.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "16    8.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "17    8.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "18    9.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "19    9.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "\n",
       "       step  \n",
       "0    1148.0  \n",
       "1    1230.0  \n",
       "2    2378.0  \n",
       "3    2460.0  \n",
       "4    3608.0  \n",
       "5    3690.0  \n",
       "6    4838.0  \n",
       "7    4920.0  \n",
       "8    6068.0  \n",
       "9    6150.0  \n",
       "10   7298.0  \n",
       "11   7380.0  \n",
       "12   8528.0  \n",
       "13   8610.0  \n",
       "14   9758.0  \n",
       "15   9840.0  \n",
       "16  10988.0  \n",
       "17  11070.0  \n",
       "18  12218.0  \n",
       "19  12300.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_files.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/v/vpa/.conda/envs/v_py3/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/global/homes/v/vpa/.conda/envs/v_py3/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute chi-sqr 337.9571421146393\n"
     ]
    }
   ],
   "source": [
    "def f_compute_chisqr(df):\n",
    "    ''' Compute chi-sqr of pixel intensity histogram for each row\n",
    "    Uses the module f_pixel_intensity to compute histograms\n",
    "    '''\n",
    "    \n",
    "    def f_chisqr(df_row,val_hist,max_val=2000):\n",
    "        ''' Compute chi-sqr of rows wrt to input data'''\n",
    "        \n",
    "        val_dr=val_hist.copy()\n",
    "        val_dr[val_dr<=0.]=1.0    ### Avoiding division by zero for zero bins\n",
    "        \n",
    "        sample=f_invtransform(df_row.images)[0]\n",
    "        ### Recomputing validation histogram to match bins with generated image\n",
    "        gen_hist,gen_err=f_pixel_intensity(sample,plot=False,normalize=False,bins=100,hist_range=(0,max_val),mode='avg')\n",
    "#         print(gen_hist)\n",
    "#         print(np.sum(gen_hist))\n",
    "        sq_diff=(gen_hist-val_hist)**2\n",
    "        ###  chi_sqr :: sum((Obs-Val)^2/(Val))\n",
    "        chi_sqr=np.sum(np.divide(sq_diff,1.0))\n",
    "        chi_sqr2=np.sum(np.divide(sq_diff,gen_err**1.0))\n",
    "#         print(chi_sqr,chi_sqr2)\n",
    "\n",
    "        return chi_sqr\n",
    "    \n",
    "    samples_input=f_invtransform(f_get_samples(df,'train_input',0,60))  ### Get input sample\n",
    "#     print(samples_input.shape)\n",
    "    \n",
    "    max_val=np.max(samples_input)\n",
    "    val_hist,val_err=f_pixel_intensity(samples_input,plot=False,normalize=False,bins=100,hist_range=(0,max_val),mode='avg')\n",
    "#     print(val_hist)\n",
    "    del samples_input\n",
    "    \n",
    "    \n",
    "    chi_sqrs=np.array(df.apply(lambda row: f_chisqr(row,val_hist=val_hist,max_val=2000), axis=1).values)\n",
    "    df['chi_sqr']=chi_sqrs\n",
    "#     print(type(chi_sqrs))\n",
    "#     print(chi_sqrs.shape,chi_sqrs[0])\n",
    "#     df['chi_sqr'],df['chi_sqr2']=chi_sqrs[0],chi_sqrs[1]\n",
    "    return df\n",
    "\n",
    "\n",
    "t1=time.time()\n",
    "# df1=f_compute_chisqr(df.loc[[0,1,2,3,300,301,303,304,600,601]])\n",
    "df1=f_compute_chisqr(df)\n",
    "t2=time.time()\n",
    "print(\"Time to compute chi-sqr\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc81e1134784b74b60b4cbfc3d3de04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 7)\n",
      "(120, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2aab1921bbe0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "# for img_type in ['val_input','val_gen','train_input','train_gen']:\n",
    "# for img_type in ['train_gen','train_input']:\n",
    "for img_type in ['val_input','val_gen']:\n",
    "    df_temp=df1[df1.img_type==img_type]\n",
    "    print(df_temp.shape)\n",
    "    plt.plot(df_temp.step.values,df_temp['chi_sqr'].values,linestyle='-',marker='*',label=img_type)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp.plot('step','chi_sqr')\n",
    "# df_temp[(df_temp.step<=66000) & (df_temp.step>56000)][['epoch','step']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epoch                 43\n",
       "step               13530\n",
       "chi_sqr      2.60107e+08\n",
       "num_large              3\n",
       "Name: 327, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.loc[df_temp['chi_sqr'].idxmin()][['epoch','step','chi_sqr','num_large']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32741a47aa6c4615b956894bf23d1da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of large pixel images from a batch set of 128 images')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Plot number of high pixel images\n",
    "# df.plot('epoch','num_large',kind='scatter')\n",
    "plt.figure()\n",
    "plt.plot(df[df.img_type=='val_gen'].step,df[df.img_type=='val_gen'].num_large,linestyle='',marker='*')\n",
    "plt.xlabel('Steps in Epochs')\n",
    "plt.ylabel('Number of large pixel images from a batch set of 128 images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore image samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_pixel_intensity(samples2,'s2',normalize=True,mode='simple',bins=50)\n",
    "# f_compare_pixel_intensity([samples2[20:60],samples4,['s2','s4'],normalize=normalize,log_scale=log_scale, mode=mode,bins=bins)\n",
    "# f_compute_spectrum(samples2)\n",
    "# f_compare_spectrum([samples2[20:60],samples4],['s2','s4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_widget_individual(df,img_type='val_gen',idx_range=(0,50),Fig_type='pixel',normalize=True,log_scale=True,rescale=True,mode='avg'):\n",
    "    '''\n",
    "    Module to plot pixel intensity or power spectrum for a given sample set of images\n",
    "    Options for normalization, log-scal, and rescale\n",
    "    Rescale converts image pixel values from (-1,1) to the original pixel range\n",
    "    2 Fig_type: pixel-> pixel intensity and spectrum -> power spectrum\n",
    "    '''\n",
    "    \n",
    "    start,end=idx_range[0],idx_range[1]\n",
    "    print('Index Range %s - %s'%(start,end))\n",
    "    \n",
    "    try :\n",
    "        sliced_arr=f_get_samples(df,img_type=img_type,start_epoch=start,end_epoch=end)\n",
    "        if sliced_arr.shape[0]<1:\n",
    "            print('Input indices %s %s are invalid.\\nUsing full array'%(start,end))\n",
    "            start0,end=0,'end'\n",
    "            sliced_arr=f_get_samples(df,img_type=img_type)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    ### Crop out large pixel values\n",
    "    sliced_arr=np.array([arr for arr in sliced_arr if np.max(arr)<=0.994])\n",
    "\n",
    "    if rescale: ### Converting from pixel intensity range (-1,1) to original range\n",
    "        sliced_arr=f_invtransform(sliced_arr)\n",
    "    print('Array size used',sliced_arr.shape)\n",
    "    \n",
    "    if Fig_type=='pixel':\n",
    "        f_pixel_intensity(sliced_arr,label=img_type+': {0}-{1}'.format(str(start),str(end)),normalize=normalize,log_scale=log_scale,mode=mode)\n",
    "    elif Fig_type=='spectrum':\n",
    "        f_compute_spectrum(sliced_arr,label=img_type+': {0}-{1}'.format(str(start),str(end)),log_scale=log_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5e15550a4c44e0bc1f0aebec2bea8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntRangeSlider(value=(0, 60), description='idx_range', max=80), ToggleButtons(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_widget_individual(df, img_type='val_gen', idx_range=(0, 50), Fig_type='pixel', normalize=True, log_scale=True, rescale=True, mode='avg')>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_manual(f_widget_individual,df=fixed(df),img_type=fixed('val_gen'),\n",
    "                Fig_type=ToggleButtons(options=['pixel','spectrum']),mode=['avg','simple'],\n",
    "                idx_range=IntRangeSlider(value=(0,60),min=0,max=80,step=1),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_widget_compare(sample_names,sample_dict,Fig_type='pixel',rescale=True,log_scale=True,bins=25,mode='avg',normalize=True):\n",
    "    '''\n",
    "    Module to make widget plots for pixel intensity or spectrum comparison for multiple sample sets\n",
    "    '''\n",
    "    \n",
    "    ### Crop out large pixel values\n",
    "    for key in sample_names:\n",
    "        print(sample_dict[key].shape)\n",
    "        sample_dict[key]=np.array([arr for arr in sample_dict[key] if np.max(arr)<=0.994])\n",
    "        print(sample_dict[key].shape)\n",
    "    \n",
    "    img_list=[sample_dict[key] for key in sample_names]\n",
    "    label_list=list(sample_names)\n",
    "        \n",
    "    hist_range=(0,0.996)\n",
    "    \n",
    "    if rescale: \n",
    "        for count,img in enumerate(img_list):\n",
    "            img_list[count]=f_invtransform(img)\n",
    "        hist_range=(0,2000)\n",
    "\n",
    "    \n",
    "    assert Fig_type in ['pixel','spectrum'],\"Invalid mode %s\"%(mode)\n",
    "    \n",
    "    if Fig_type=='pixel':\n",
    "        f_compare_pixel_intensity(img_lst=img_list,label_lst=label_list,normalize=normalize,log_scale=log_scale, mode=mode,bins=bins,hist_range=hist_range)\n",
    "    elif Fig_type=='spectrum':\n",
    "        f_compare_spectrum(img_lst=img_list,label_lst=label_list,log_scale=log_scale)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare different epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7e0f7dad55465f9433e386b072eaa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='sample_names', options=('0:5', '5:10', '10:15', '15:20', '20…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_widget_compare(sample_names, sample_dict, Fig_type='pixel', rescale=True, log_scale=True, bins=25, mode='avg', normalize=True)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img_list,labels_list=f_get_sample_epochs(df,'val_gen',10)\n",
    "\n",
    "img_list,labels_list=[],[]\n",
    "# for epoch_range in [(0,4),(17,20),(25,27),(34,37),(44,51),(53,59)]:\n",
    "for epoch_range in [(i,i+5) for i in range(0,60,5)]:\n",
    "    start,end=epoch_range[0],epoch_range[1]\n",
    "    img_list.append(f_get_samples(df,'val_gen',start,end))\n",
    "    labels_list.append('%s:%s'%(str(start),str(end)))\n",
    "\n",
    "dict_samples=dict.fromkeys(labels_list)\n",
    "for key,val in zip(labels_list,img_list): dict_samples[key]=val\n",
    "\n",
    "### Compare with input\n",
    "dict_samples['val input']=f_get_samples(df,img_type='val_input')\n",
    "interact_manual(f_widget_compare,sample_dict=fixed(dict_samples),\n",
    "                sample_names=SelectMultiple(options=dict_samples.keys()),\n",
    "                Fig_type=ToggleButtons(options=['pixel','spectrum']),bins=IntText(value=50),mode=['avg','simple'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare image types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999325\n"
     ]
    }
   ],
   "source": [
    "### Available options : keys=['train_gen','train_input','val_gen','val_input']\n",
    "start,end=36,37\n",
    "samples1=f_get_samples(df,'val_gen',start,end)\n",
    "samples2=f_get_samples(df,'val_input',0,60)\n",
    "samples3=f_get_samples(df,'train_gen',start,end)\n",
    "samples4=f_get_samples(df,'train_input')\n",
    "\n",
    "print(np.max(samples1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de68dc045134151a806c0101e604a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='sample_names', options=('s1', 's2', 's3', 's4'), value=()), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_widget_compare(sample_names, sample_dict, Fig_type='pixel', rescale=True, log_scale=True, bins=25, mode='avg', normalize=True)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_samples={'s1':samples1, 's2': samples2, 's3': samples3, 's4':samples4}\n",
    "interact_manual(f_widget_compare,sample_dict=fixed(dict_samples),\n",
    "                sample_names=SelectMultiple(options=dict_samples.keys()),\n",
    "                Fig_type=ToggleButtons(options=['pixel','spectrum']),bins=IntText(value=50),mode=['avg','simple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_py3",
   "language": "python",
   "name": "v_jpt_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from output files\n",
    "### Analyze the output from a single LBANN run\n",
    "March 9, 2020 \\\n",
    "April 6, 2020 : Major edit to store files in order of epochs \\\n",
    "April 21, 2020: Major edit, added jupyter widgets to compare pixel intensity plots\n",
    "\n",
    "May 8, 2020: Major edit, using all images for a given batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import subprocess as sp\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import time\n",
    "from scipy import fftpack\n",
    "# from ipywidgets import interact, interact_manual,fixed, SelectMultiple, IntText, IntSlider, FloatSlider,SelectionSlider,BoundedIntText\n",
    "from ipywidgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook modules_image_analysis.ipynb to script\n",
      "[NbConvertApp] Writing 15103 bytes to modules_image_analysis.py\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/LBANN/lbann_cosmogan/3_analysis/')\n",
    "from modules_image_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8233713303851306"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Transformation functions for image pixel values\n",
    "\n",
    "def f_transform_new(x):\n",
    "    if x<=50:\n",
    "        a=0.03; b=-1.0\n",
    "        return a*x+b\n",
    "    elif x>50: \n",
    "        a=0.5/np.log(300)\n",
    "        b=0.5-a*np.log(50)\n",
    "        return a*np.log(x)+b\n",
    "\n",
    "def f_invtransform_new(y):\n",
    "    if y<=0.5:\n",
    "        a=0.03;b=-1.0\n",
    "        return (y-b)/a\n",
    "    elif y>0.5: \n",
    "        a=0.5/np.log(300)\n",
    "        b=0.5-a*np.log(50)\n",
    "        return np.exp((y-b)/a)\n",
    "    \n",
    "\n",
    "def f_transform(x):\n",
    "    return np.vectorize(f_transform_new)(x)\n",
    "\n",
    "def f_invtransform(s):\n",
    "    return np.vectorize(f_invtransform_new)(s)\n",
    "\n",
    "f_transform_new(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules for Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_get_files_df_sorted():\n",
    "    '''\n",
    "    Module to create Dataframe with filenames for each epoch and step\n",
    "    Sorts by step and epoch\n",
    "    '''\n",
    "    \n",
    "    ## Get images files and .npy arrays for each image in dump_outs folder\n",
    "    t1=time.time()\n",
    "    files_dict={}\n",
    "    keys=['train_gen','train_input','val_gen','val_input']\n",
    "    file_strg_lst=['model0-training*-gen_img*-output0.npy','model0-training*-inp_img*-output0.npy','model0-validation*-gen_img*-output0.npy','model0-validation*-inp_img*-output0.npy']\n",
    "    for key,file_strg in zip(keys,file_strg_lst):\n",
    "        files_dict[key]=np.array(glob.glob(main_dir+file_strg))\n",
    "        if files_dict[key].shape[0]>1000 : \n",
    "            print('Warning the number of files is very large. Possibility of memory overload')\n",
    "\n",
    "    df_files=pd.DataFrame([])\n",
    "    dict1={}\n",
    "    t1=time.time()\n",
    "    ### First get sorted Dataframe with file names\n",
    "    for key in keys: \n",
    "        files_arr=files_dict[key]  # Get array of files\n",
    "        print(key,len(files_arr))\n",
    "        for fname in files_arr:\n",
    "            ### Extract the Epoch number and step number from the file name\n",
    "            dict1['img_type']=key\n",
    "            dict1['epoch']=np.int32(fname.split('epoch')[-1].split('-')[0])\n",
    "            dict1['step']=np.int64(fname.split('step')[-1].split('-')[0])\n",
    "            dict1['fname']=fname\n",
    "\n",
    "            df_files=df_files.append(dict1,ignore_index=True)\n",
    "    ## Sort values\n",
    "    df_files=df_files.sort_values(by=['img_type','epoch','step']).reset_index(drop=True)\n",
    "    # df_files\n",
    "    t2=time.time()\n",
    "    print(\"Time for Sorting\",t2-t1)\n",
    "    \n",
    "    return df_files\n",
    "\n",
    "\n",
    "def f_filter_epoch(df_input,num_sliced=1):\n",
    "    '''\n",
    "    Get just the last few stored step images for each epoch\n",
    "    '''\n",
    "    print('Extracting last %s steps of each epoch'%(num_sliced))\n",
    "    df_output=pd.DataFrame([])\n",
    "    for key in ['train_gen','train_input','val_gen','val_input']: \n",
    "        ### For each type of images, get list of epochs\n",
    "        df1=df_input[df_input.img_type==key]\n",
    "        epochs=np.unique(df1.epoch.values).astype(int)\n",
    "\n",
    "        for epoch in epochs:### Extract the last few steps in each epoch\n",
    "            df2=df1[df1.epoch==epoch]\n",
    "            df_output=df_output.append(df2.iloc[-num_sliced:])  \n",
    "    \n",
    "    return df_output.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def f_get_images_df(df_files):\n",
    "    '''\n",
    "    Read dataframe with file names, read files and create new dataframe with images as numpy arrays\n",
    "    Also computes number of images with intensity beyond a cutoff\n",
    "    '''\n",
    "    \n",
    "    def f_row(df_row):\n",
    "        '''\n",
    "        Extract image\n",
    "        '''\n",
    "        fname,key=df_row.fname,df_row.img_type\n",
    "        a1=np.load(fname)\n",
    "        if key.endswith('input'): \n",
    "            size=np.int(np.sqrt(a1.shape[-1])) ### Extract size of images (=128)\n",
    "            batch_size=a1.shape[0] ### Number of batches\n",
    "            samples=a1.reshape(batch_size,size,size)\n",
    "        elif key.endswith('gen') : samples=a1[:,0,:,:]\n",
    "        else : raise SystemError\n",
    "\n",
    "        return samples\n",
    "    \n",
    "    def f_high_pixel(df_row,cutoff=0.9966):\n",
    "        '''\n",
    "        Get number of images with a pixel about max cut-off value\n",
    "        '''\n",
    "        max_arr=np.amax(df_row.images,axis=(1,2))\n",
    "        num_large=max_arr[max_arr>cutoff].shape[0]\n",
    "\n",
    "        return num_large\n",
    "    \n",
    "    t1=time.time()\n",
    "    ##### Create new Dataframe with sorted images\n",
    "    df=df_files.copy()\n",
    "    df['images']=df.apply(lambda row: f_row(row), axis=1)\n",
    "    t2=time.time()\n",
    "    print(\"Time for Reading images\",t2-t1)\n",
    "    \n",
    "    ### Store the number of images with large pixel value\n",
    "    cutoff=0.82337\n",
    "    df['num_large']=df.apply(lambda row: f_high_pixel(row,cutoff), axis=1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def f_get_sample_epochs(df,img_type,start_epoch=None,end_epoch=None):\n",
    "    '''\n",
    "    Module to extract images for a range of epochs given a dataframe\n",
    "    '''\n",
    "    if start_epoch==None and end_epoch==None:\n",
    "        max_epoch=np.int(np.max(df.epoch.values))\n",
    "#         print(max_epoch)\n",
    "        start_epoch=0; end_epoch=max_epoch\n",
    "#     if end_epoch==None: end_epoch=start_epoch+1\n",
    "    \n",
    "    arr=df[(df.epoch>=start_epoch) & (df.epoch<=end_epoch) & (df.img_type==img_type)].images.values\n",
    "    arr=np.vstack(arr)\n",
    "#     print(arr.shape,np.max(arr))    \n",
    "    \n",
    "    return arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract image data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/20200518_200316_new_transform_mcr/dump_outs/\n"
     ]
    }
   ],
   "source": [
    "fldr_name='20200516_183817_new_trans_no_mcr'\n",
    "fldr_name='20200518_200316_new_transform_mcr'\n",
    "main_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/{0}/dump_outs/'.format(fldr_name)\n",
    "print(main_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_gen 902\n",
      "train_input 902\n",
      "val_gen 226\n",
      "val_input 226\n",
      "Time for Sorting 24.669420957565308\n",
      "Extracting last 5 steps of each epoch\n",
      "Time for Reading images 151.93386220932007\n",
      "(1052, 6)\n",
      "Extracting last 1 steps of each epoch\n"
     ]
    }
   ],
   "source": [
    "### Get dataframe with file names, sorted by epoch and step\n",
    "df_files=f_get_files_df_sorted()\n",
    "\n",
    "### Slice out rows to keep only the last few steps for each epoch.\n",
    "df_files=f_filter_epoch(df_files,num_sliced=5)\n",
    "\n",
    "#############################################################\n",
    "### Read images one by one into a numpy array and create a new DataFrame\n",
    "df=f_get_images_df(df_files)\n",
    "print(df.shape)\n",
    "\n",
    "# ### Filter to keep just one step per epoch\n",
    "df=f_filter_epoch(df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>fname</th>\n",
       "      <th>img_type</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>902.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>1066.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>1148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>1230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>2132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>2214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>2296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>2378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>2460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>3362.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>3444.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>3526.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>3608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>3690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>4592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>4674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>4756.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>4838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.0</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>4920.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch                                              fname   img_type  \\\n",
       "0     0.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "1     0.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "2     0.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "3     0.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "4     0.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "5     1.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "6     1.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "7     1.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "8     1.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "9     1.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "10    2.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "11    2.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "12    2.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "13    2.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "14    2.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "15    3.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "16    3.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "17    3.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "18    3.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "19    3.0  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...  train_gen   \n",
       "\n",
       "      step  \n",
       "0    902.0  \n",
       "1    984.0  \n",
       "2   1066.0  \n",
       "3   1148.0  \n",
       "4   1230.0  \n",
       "5   2132.0  \n",
       "6   2214.0  \n",
       "7   2296.0  \n",
       "8   2378.0  \n",
       "9   2460.0  \n",
       "10  3362.0  \n",
       "11  3444.0  \n",
       "12  3526.0  \n",
       "13  3608.0  \n",
       "14  3690.0  \n",
       "15  4592.0  \n",
       "16  4674.0  \n",
       "17  4756.0  \n",
       "18  4838.0  \n",
       "19  4920.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_files.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "<class 'numpy.ndarray'>\n",
      "Time to compute chi-sqr 705.0654833316803\n"
     ]
    }
   ],
   "source": [
    "def f_compute_chisqr(df):\n",
    "    ''' Compute chi-sqr of pixel intensity histogram for each row\n",
    "    Uses the module f_pixel_intensity to compute histograms\n",
    "    '''\n",
    "    \n",
    "    def f_chisqr(df_row,val_hist,val_err,max_val=2000):\n",
    "        ''' Compute chi-sqr of rows wrt to input data'''\n",
    "        \n",
    "        val_dr=val_hist.copy()\n",
    "        val_dr[val_dr<=0.]=1.0    ### Avoiding division by zero for zero bins\n",
    "#         print(val_dr)\n",
    "        sample=f_invtransform(df_row.images)[0]\n",
    "        ### Compute pixel histogram for row   ### !!! Ensure both pixel histograms have save bins and normalization !!! ###\n",
    "        gen_hist,gen_err=f_pixel_intensity(sample,plot=False,normalize=True,bins=50,hist_range=(0,max_val),mode='avg')\n",
    "        ### Compute chi-sqr\n",
    "        sq_diff=(gen_hist-val_hist)**2\n",
    "        ###  chi_sqr :: sum((Obs-Val)^2/(Val))\n",
    "        chi_sqr1=np.sum(np.divide(sq_diff,val_dr**2))\n",
    "        chi_sqr2=np.sum(np.divide(sq_diff,1.0))\n",
    "        chi_sqr3=np.sum(gen_err)/np.sum(val_err)  ## measures total spread in histograms wrt to input data\n",
    "        \n",
    "        return chi_sqr1,chi_sqr2,chi_sqr3\n",
    "    \n",
    "    ### Get pixel histogram of all input data\n",
    "    samples_input=f_invtransform(f_get_sample_epochs(df,'train_input'))    \n",
    "    max_val=np.max(samples_input)\n",
    "    val_hist,val_err=f_pixel_intensity(samples_input,plot=False,normalize=True,bins=50,hist_range=(0,max_val),mode='avg')\n",
    "    del samples_input\n",
    "    \n",
    "    ### Get chi-sqr for each row (step-epoch) for generated data\n",
    "    chi_sqrs=df.apply(lambda row: f_chisqr(row,val_hist=val_hist,val_err=val_err,max_val=2000), axis=1).values\n",
    "    chi_vals=np.array(list(zip(*chi_sqrs)))  ## transposing list of list \n",
    "\n",
    "    df['chi_sqr1'],df['chi_sqr2'],df['chi_sqr3']=chi_vals[0],chi_vals[1],chi_vals[2]\n",
    "    print(type(chi_sqrs))\n",
    "    \n",
    "    return df\n",
    "\n",
    "t1=time.time()\n",
    "# df1=f_compute_chisqr(df.loc[[0,1,2,3,100,200]])\n",
    "df1=f_compute_chisqr(df)\n",
    "t2=time.time()\n",
    "print(\"Time to compute chi-sqr\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98b8a4e91864985bb94c5a532c090e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 9)\n",
      "(60, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Step')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "# for img_type in ['val_input','val_gen','train_input','train_gen']:\n",
    "# for img_type in ['train_gen','train_input']:\n",
    "for img_type in ['val_input','val_gen']:\n",
    "    df_temp=df1[df1.img_type==img_type]\n",
    "    print(df_temp.shape)\n",
    "    plt.plot(df_temp.step.values,df_temp['chi_sqr3'].values,linestyle='-',marker='*',label=img_type)\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Chisquare')\n",
    "plt.xlabel('Step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp.groupby(['epoch','chi_sqr'],as_index=False).last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e787e5c3f24bd7b381f20b504c441b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 9)\n",
      "(60, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/v/vpa/.conda/envs/v_py3/lib/python3.6/site-packages/ipykernel_launcher.py:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  import sys\n",
      "/global/homes/v/vpa/.conda/envs/v_py3/lib/python3.6/site-packages/ipykernel_launcher.py:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/global/homes/v/vpa/.conda/envs/v_py3/lib/python3.6/site-packages/ipykernel_launcher.py:15: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(10,3))\n",
    "# for img_type in ['val_input','val_gen','train_input','train_gen']:\n",
    "# for img_type in ['train_gen','train_input']:\n",
    "for img_type in ['val_input','val_gen']:\n",
    "    df_temp=df1[df1.img_type==img_type]\n",
    "    print(df_temp.shape)\n",
    "    fig.add_subplot(1,3,1)\n",
    "    plt.plot(df_temp.epoch.values,df_temp['chi_sqr1'].values,linestyle='-',marker='*',label=img_type)\n",
    "    plt.title('chisqr1')\n",
    "    \n",
    "    fig.add_subplot(1,3,2)\n",
    "    plt.plot(df_temp.epoch.values,df_temp['chi_sqr2'].values,linestyle='-',marker='*',label=img_type)\n",
    "    plt.title('chisqr2')\n",
    "\n",
    "    fig.add_subplot(1,3,3)\n",
    "    plt.plot(df_temp.epoch.values,df_temp['chi_sqr3'].values,linestyle='-',marker='*',label=img_type)\n",
    "    plt.title('Deviation in histograms')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp.plot('step','chi_sqr')\n",
    "# df_temp[(df_temp.step<=66000) & (df_temp.step>56000)][['epoch','step']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.loc[df_temp['chi_sqr'].idxmin()][['epoch','step','chi_sqr','num_large']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot number of high pixel images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b214febbbf204708a2c66e4e6ce4a884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of large pixel images from a batch set of 128 images')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.plot('epoch','num_large',kind='scatter')\n",
    "plt.figure()\n",
    "plt.plot(df[df.img_type=='val_gen'].step,df[df.img_type=='val_gen'].num_large,linestyle='',marker='*')\n",
    "plt.xlabel('Steps in Epochs')\n",
    "plt.ylabel('Number of large pixel images from a batch set of 128 images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore image samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_widget_individual(df,img_type='val_gen',idx_range=(0,50),Fig_type='pixel',normalize=True,log_scale=True,rescale=True,mode='avg'):\n",
    "    '''\n",
    "    Module to plot pixel intensity or power spectrum for a given sample set of images\n",
    "    Options for normalization, log-scal, and rescale\n",
    "    Rescale converts image pixel values from (-1,1) to the original pixel range\n",
    "    2 Fig_type: pixel-> pixel intensity and spectrum -> power spectrum\n",
    "    '''\n",
    "    \n",
    "    start,end=idx_range[0],idx_range[1]\n",
    "    print('Index Range %s - %s'%(start,end))\n",
    "    \n",
    "    try :\n",
    "        sliced_arr=f_get_sample_epochs(df,img_type=img_type,start_epoch=start,end_epoch=end)\n",
    "        if sliced_arr.shape[0]<1:\n",
    "            print('Input indices %s %s are invalid.\\nUsing full array'%(start,end))\n",
    "            start0,end=0,'end'\n",
    "            sliced_arr=f_get_sample_epochs(df,img_type=img_type)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    ### Crop out large pixel values\n",
    "    sliced_arr=np.array([arr for arr in sliced_arr if np.max(arr)<=0.994])\n",
    "\n",
    "    if rescale: ### Converting from pixel intensity range (-1,1) to original range\n",
    "        sliced_arr=f_invtransform(sliced_arr)\n",
    "    print('Array size used',sliced_arr.shape)\n",
    "    \n",
    "    if Fig_type=='pixel':\n",
    "        f_pixel_intensity(sliced_arr,label=img_type+': {0}-{1}'.format(str(start),str(end)),normalize=normalize,log_scale=log_scale,mode=mode)\n",
    "    elif Fig_type=='spectrum':\n",
    "        f_compute_spectrum(sliced_arr,label=img_type+': {0}-{1}'.format(str(start),str(end)),log_scale=log_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(f_widget_individual,df=fixed(df),img_type=fixed('val_gen'),\n",
    "                Fig_type=ToggleButtons(options=['pixel','spectrum']),mode=['avg','simple'],\n",
    "                idx_range=IntRangeSlider(value=(0,60),min=0,max=80,step=1),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_widget_compare(sample_names,sample_dict,Fig_type='pixel',rescale=True,log_scale=True,bins=25,mode='avg',normalize=True):\n",
    "    '''\n",
    "    Module to make widget plots for pixel intensity or spectrum comparison for multiple sample sets\n",
    "    '''\n",
    "    \n",
    "    ### Crop out large pixel values\n",
    "    for key in sample_names:\n",
    "#         print(sample_dict[key].shape)\n",
    "        sample_dict[key]=np.array([arr for arr in sample_dict[key] if np.max(arr)<=0.994])\n",
    "#         print(sample_dict[key].shape)\n",
    "    \n",
    "    img_list=[sample_dict[key] for key in sample_names]\n",
    "    label_list=list(sample_names)\n",
    "        \n",
    "#     hist_range=(0,0.996)\n",
    "    \n",
    "    if rescale: \n",
    "        for count,img in enumerate(img_list):\n",
    "            img_list[count]=f_invtransform(img)\n",
    "#         hist_range=(0,2000)\n",
    "\n",
    "    assert Fig_type in ['pixel','spectrum'],\"Invalid mode %s\"%(mode)\n",
    "    \n",
    "    if Fig_type=='pixel':\n",
    "        f_compare_pixel_intensity(img_lst=img_list,label_lst=label_list,normalize=normalize,log_scale=log_scale, mode=mode,bins=bins,hist_range=None)\n",
    "    elif Fig_type=='spectrum':\n",
    "        f_compare_spectrum(img_lst=img_list,label_lst=label_list,log_scale=log_scale)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare different epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_get_sample_epochs(df,img_type='val_input').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d672d322994acdaabd2721ddce9a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='sample_names', options=('0:5', '5:10', '10:15', '15:20', '20…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_widget_compare(sample_names, sample_dict, Fig_type='pixel', rescale=True, log_scale=True, bins=25, mode='avg', normalize=True)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img_list,labels_list=f_get_sample_epochs(df,'val_gen',10)\n",
    "\n",
    "img_list,labels_list=[],[]\n",
    "# for epoch_range in [(0,4),(17,20),(25,27),(34,37),(44,51),(53,59)]:\n",
    "for epoch_range in [(i,i+5) for i in range(0,60,5)]:\n",
    "    start,end=epoch_range[0],epoch_range[1]\n",
    "    img_list.append(f_get_sample_epochs(df,'val_gen',start,end))\n",
    "    labels_list.append('%s:%s'%(str(start),str(end)))\n",
    "\n",
    "dict_samples=dict.fromkeys(labels_list)\n",
    "for key,val in zip(labels_list,img_list): dict_samples[key]=val\n",
    "\n",
    "### Compare with input\n",
    "dict_samples['val input']=f_get_sample_epochs(df,img_type='val_input')\n",
    "\n",
    "### Widget for comparison plots\n",
    "interact_manual(f_widget_compare,sample_dict=fixed(dict_samples),\n",
    "                sample_names=SelectMultiple(options=dict_samples.keys()),\n",
    "                Fig_type=ToggleButtons(options=['pixel','spectrum']),bins=IntText(value=50),mode=['avg','simple'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare image types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "0.78496647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(640, 128, 128)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Available options : keys=['train_gen','train_input','val_gen','val_input']\n",
    "start,end=55,60\n",
    "samples1=f_get_sample_epochs(df,'val_gen',start,end)\n",
    "samples2=f_get_sample_epochs(df,'val_input',0,60)\n",
    "samples3=f_get_sample_epochs(df,'train_gen',start,end)\n",
    "samples4=f_get_sample_epochs(df,'train_input')\n",
    "\n",
    "print(np.max(samples1))\n",
    "samples1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8186d6bfdc7c409ba1ca16c77a196257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='sample_names', options=('s1', 's2', 's3', 's4'), value=()), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_widget_compare(sample_names, sample_dict, Fig_type='pixel', rescale=True, log_scale=True, bins=25, mode='avg', normalize=True)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_samples={'s1':samples1, 's2': samples2, 's3': samples3, 's4':samples4}\n",
    "interact_manual(f_widget_compare,sample_dict=fixed(dict_samples),\n",
    "                sample_names=SelectMultiple(options=dict_samples.keys()),\n",
    "                Fig_type=ToggleButtons(options=['pixel','spectrum']),bins=IntText(value=50),mode=['avg','simple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_py3",
   "language": "python",
   "name": "v_jpt_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

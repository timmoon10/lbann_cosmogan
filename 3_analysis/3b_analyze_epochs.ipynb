{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from output files\n",
    "### Analyze the output from a single LBANN run\n",
    "March 9, 2020 \n",
    "April 6, 2020 : to store files in order of epochs \\\n",
    "April 21, 2020: added jupyter widgets to compare pixel intensity plots \\\n",
    "May 8, 2020: using all images for a given batch \\\n",
    "May 29, 2020: Modified for new update of LBANN. File names of images changed, so new extraction code. Also added code for computing chi-squared. \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import subprocess as sp\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import time\n",
    "from scipy import fftpack\n",
    "# from ipywidgets import interact, interact_manual,fixed, SelectMultiple, IntText, IntSlider, FloatSlider,SelectionSlider,BoundedIntText\n",
    "from ipywidgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook modules_image_analysis.ipynb to script\n",
      "[NbConvertApp] Writing 15101 bytes to modules_image_analysis.py\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/LBANN/lbann_cosmogan/3_analysis/')\n",
    "from modules_image_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transformation functions for image pixel values\n",
    "def f_transform(x):\n",
    "    return 2.*x/(x + 4. + 1e-8) - 1.\n",
    "\n",
    "def f_invtransform(s):\n",
    "    return 4.*(1. + s)/(1. - s + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Other transformatino functinos\n",
    "# ### Transformation functions for image pixel values\n",
    "\n",
    "# def f_transform_new(x):\n",
    "#     if x<=50:\n",
    "#         a=0.03; b=-1.0\n",
    "#         return a*x+b\n",
    "#     elif x>50: \n",
    "#         a=0.5/np.log(300)\n",
    "#         b=0.5-a*np.log(50)\n",
    "#         return a*np.log(x)+b\n",
    "\n",
    "# def f_invtransform_new(y):\n",
    "#     if y<=0.5:\n",
    "#         a=0.03;b=-1.0\n",
    "#         return (y-b)/a\n",
    "#     elif y>0.5: \n",
    "#         a=0.5/np.log(300)\n",
    "#         b=0.5-a*np.log(50)\n",
    "#         return np.exp((y-b)/a)\n",
    "    \n",
    "\n",
    "# def f_transform(x):\n",
    "#     return np.vectorize(f_transform_new)(x)\n",
    "\n",
    "# def f_invtransform(s):\n",
    "#     return np.vectorize(f_invtransform_new)(s)\n",
    "\n",
    "# f_transform_new(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules for Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_get_files_df_sorted():\n",
    "    '''\n",
    "    Module to create Dataframe with filenames for each epoch and step\n",
    "    Sorts by step and epoch\n",
    "    '''\n",
    "    \n",
    "    ## Get images files and .npy arrays for each image in dump_outs folder\n",
    "    t1=time.time()\n",
    "    files_dict={}\n",
    "    keys=['train_gen','train_input','val_gen','val_input']\n",
    "#     file_strg_lst=['model0-training*-gen_img*-output0.npy','model0-training*-inp_img*-output0.npy','model0-validation*-gen_img*-output0.npy','model0-validation*-inp_img*-output0.npy']\n",
    "    file_strg_lst=['sgd.training*_gen_img*_output0.npy','sgd.training*_inp_img*_output0.npy','sgd.validation*_gen_img*_output0.npy','sgd.validation*_inp_img*_output0.npy']\n",
    "\n",
    "    for key,file_strg in zip(keys,file_strg_lst):\n",
    "        files_dict[key]=np.array(glob.glob(main_dir+file_strg))\n",
    "        if files_dict[key].shape[0]>1000 : \n",
    "            print('Warning the number of files is very large. Possibility of memory overload')\n",
    "    \n",
    "    df_files=pd.DataFrame([])\n",
    "    dict1={}\n",
    "    t1=time.time()\n",
    "    ### First get sorted Dataframe with file names\n",
    "    for key in keys:\n",
    "        files_arr=files_dict[key]  # Get array of files\n",
    "        print(key,len(files_arr))\n",
    "        for fname in files_arr:\n",
    "            ### Extract the Epoch number and step number from the file name\n",
    "            dict1['img_type']=key\n",
    "#             dict1['epoch']=np.int32(fname.split('epoch')[-1].split('-')[0])\n",
    "#             dict1['step']=np.int64(fname.split('step')[-1].split('-')[0])\n",
    "            dict1['epoch']=np.int32(fname.split('epoch')[-1].split('.')[1])\n",
    "            dict1['step']=np.int64(fname.split('step')[-1].split('.')[1].split('_')[0])\n",
    "            dict1['fname']=fname\n",
    "            \n",
    "            df_files=df_files.append(dict1,ignore_index=True)\n",
    "    ## Sort values\n",
    "    df_files=df_files.sort_values(by=['img_type','epoch','step']).reset_index(drop=True)\n",
    "    # df_files\n",
    "    t2=time.time()\n",
    "    print(\"Time for Sorting\",t2-t1)\n",
    "    \n",
    "    return df_files\n",
    "\n",
    "\n",
    "def f_filter_epoch(df_input,num_sliced=1):\n",
    "    '''\n",
    "    Get just the last few stored step images for each epoch\n",
    "    '''\n",
    "    print('Extracting last %s steps of each epoch'%(num_sliced))\n",
    "    df_output=pd.DataFrame([])\n",
    "    for key in ['train_gen','train_input','val_gen','val_input']: \n",
    "        ### For each type of images, get list of epochs\n",
    "        df1=df_input[df_input.img_type==key]\n",
    "        epochs=np.unique(df1.epoch.values).astype(int)\n",
    "\n",
    "        for epoch in epochs:### Extract the last few steps in each epoch\n",
    "            df2=df1[df1.epoch==epoch]\n",
    "            df_output=df_output.append(df2.iloc[-num_sliced:])  \n",
    "    \n",
    "    return df_output.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def f_get_images_df(df_files):\n",
    "    '''\n",
    "    Read dataframe with file names, read files and create new dataframe with images as numpy arrays\n",
    "    Also computes number of images with intensity beyond a cutoff\n",
    "    '''\n",
    "    \n",
    "    def f_row(df_row):\n",
    "        '''\n",
    "        Extract image\n",
    "        '''\n",
    "        fname,key=df_row.fname,df_row.img_type\n",
    "        a1=np.load(fname)\n",
    "        if key.endswith('input'): \n",
    "            size=np.int(np.sqrt(a1.shape[-1])) ### Extract size of images (=128)\n",
    "            batch_size=a1.shape[0] ### Number of batches\n",
    "            samples=a1.reshape(batch_size,size,size)\n",
    "        elif key.endswith('gen') : samples=a1[:,0,:,:]\n",
    "        else : raise SystemError\n",
    "\n",
    "        return samples\n",
    "    \n",
    "    def f_high_pixel(df_row,cutoff=0.9966):\n",
    "        '''\n",
    "        Get number of images with a pixel about max cut-off value\n",
    "        '''\n",
    "        max_arr=np.amax(df_row.images,axis=(1,2))\n",
    "        num_large=max_arr[max_arr>cutoff].shape[0]\n",
    "\n",
    "        return num_large\n",
    "    \n",
    "    t1=time.time()\n",
    "    ##### Create new Dataframe with sorted images\n",
    "    df=df_files.copy()\n",
    "    df['images']=df.apply(lambda row: f_row(row), axis=1)\n",
    "    t2=time.time()\n",
    "    print(\"Time for Reading images\",t2-t1)\n",
    "    \n",
    "    ### Store the number of images with large pixel value\n",
    "    cutoff=0.9966\n",
    "    df['num_large']=df.apply(lambda row: f_high_pixel(row,cutoff), axis=1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def f_get_sample_epochs(df,img_type,start_epoch=None,end_epoch=None):\n",
    "    '''\n",
    "    Module to extract images for a range of epochs given a dataframe\n",
    "    '''\n",
    "    if start_epoch==None and end_epoch==None:\n",
    "        max_epoch=np.int(np.max(df.epoch.values))\n",
    "        print(max_epoch)\n",
    "        start_epoch=0; end_epoch=max_epoch\n",
    "#     if end_epoch==None: end_epoch=start_epoch+1\n",
    "    \n",
    "    arr=df[(df.epoch>=start_epoch) & (df.epoch<=end_epoch) & (df.img_type==img_type)].images.values\n",
    "    arr=np.vstack(arr)\n",
    "    \n",
    "    return arr\n",
    "\n",
    "\n",
    "def f_compute_chisqr(df):\n",
    "    ''' Compute chi-sqr of pixel intensity histogram for each row\n",
    "    Uses the module f_pixel_intensity to compute histograms\n",
    "    '''\n",
    "    \n",
    "    def f_chisqr(df_row,val_hist,val_err,max_val=2000):\n",
    "        ''' Compute chi-sqr of rows wrt to input data'''\n",
    "        \n",
    "        val_dr=val_hist.copy()\n",
    "        val_dr[val_dr<=0.]=1.0    ### Avoiding division by zero for zero bins\n",
    "#         print(val_dr)\n",
    "        sample=f_invtransform(df_row.images)[0]\n",
    "        ### Compute pixel histogram for row   ### !!! Ensure both pixel histograms have save bins and normalization !!! ###\n",
    "        gen_hist,gen_err=f_pixel_intensity(sample,plot=False,normalize=True,bins=50,hist_range=(0,max_val),mode='avg')\n",
    "        ### Compute chi-sqr\n",
    "        sq_diff=(gen_hist-val_hist)**2\n",
    "        ###  chi_sqr :: sum((Obs-Val)^2/(Val))\n",
    "        chi_sqr1=np.sum(np.divide(sq_diff[:25],val_dr[:25]**2))\n",
    "        chi_sqr2=np.sum(np.divide(sq_diff[:25],1.0))\n",
    "        chi_sqr3=np.sum(gen_err[:25])/np.sum(val_err[:25])  ## measures total spread in histograms wrt to input data\n",
    "        \n",
    "        return chi_sqr1,chi_sqr2,chi_sqr3\n",
    "    \n",
    "    ### Get pixel histogram of all input data\n",
    "    samples_input=f_invtransform(f_get_sample_epochs(df,'train_input'))    \n",
    "    max_val=np.max(samples_input)\n",
    "    val_hist,val_err=f_pixel_intensity(samples_input,plot=False,normalize=True,bins=50,hist_range=(0,max_val),mode='avg')\n",
    "    del samples_input\n",
    "    \n",
    "    ### Get chi-sqr for each row (step-epoch) for generated data\n",
    "    chi_sqrs=df.apply(lambda row: f_chisqr(row,val_hist=val_hist,val_err=val_err,max_val=2000), axis=1).values\n",
    "    chi_vals=np.array(list(zip(*chi_sqrs)))  ## transposing list of list \n",
    "\n",
    "    df['chi_sqr1'],df['chi_sqr2'],df['chi_sqr3']=chi_vals[0],chi_vals[1],chi_vals[2]\n",
    "    print(type(chi_sqrs))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract image data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/20200529_111342_seed3273_80epochs/dump_outs/trainer0/model0/\n"
     ]
    }
   ],
   "source": [
    "fldr_name='20200529_063053_seed232_80epochs'\n",
    "fldr_name='20200529_090232_seed17278_80epochs'\n",
    "fldr_name='20200529_111342_seed3273_80epochs'\n",
    "# fldr_name='20200601_150741_seed2020_200epochs'\n",
    "main_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/{0}/dump_outs/trainer0/model0/'.format(fldr_name)\n",
    "print(main_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning the number of files is very large. Possibility of memory overload\n",
      "Warning the number of files is very large. Possibility of memory overload\n",
      "train_gen 1202\n",
      "train_input 1202\n",
      "val_gen 301\n",
      "val_input 301\n",
      "Time for Sorting 10.013043403625488\n",
      "Time for Reading images 216.58686327934265\n",
      "(3006, 6)\n"
     ]
    }
   ],
   "source": [
    "### Get dataframe with file names, sorted by epoch and step\n",
    "df_files=f_get_files_df_sorted()\n",
    "\n",
    "### Slice out rows to keep only the last few steps for each epoch.\n",
    "# df_files=f_filter_epoch(df_files,num_sliced=2)\n",
    "\n",
    "#############################################################\n",
    "### Read images one by one into a numpy array and create a new DataFrame\n",
    "df_full=f_get_images_df(df_files)\n",
    "print(df_full.shape)\n",
    "\n",
    "# ### Filter to keep just one step per epoch\n",
    "# df_full=f_filter_epoch(df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full=df_full.loc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>img_type</th>\n",
       "      <th>fname</th>\n",
       "      <th>num_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>79.0</td>\n",
       "      <td>24518.0</td>\n",
       "      <td>val_input</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>79.0</td>\n",
       "      <td>24600.0</td>\n",
       "      <td>val_input</td>\n",
       "      <td>/global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      epoch     step   img_type  \\\n",
       "0       0.0      0.0  train_gen   \n",
       "1       0.0     82.0  train_gen   \n",
       "3004   79.0  24518.0  val_input   \n",
       "3005   79.0  24600.0  val_input   \n",
       "\n",
       "                                                  fname  num_large  \n",
       "0     /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...          0  \n",
       "1     /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...          0  \n",
       "3004  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...          0  \n",
       "3005  /global/cfs/cdirs/m3363/vayyar/cosmogan_data/r...          0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_files.head(20)\n",
    "df_full[['epoch','step','img_type','fname','num_large']].iloc[[0,1,-2,-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "<class 'numpy.ndarray'>\n",
      "Time to compute chi-sqr 176.98170971870422\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "# df1=f_compute_chisqr(df.loc[[0,1,2,3,100,200]])\n",
    "df_full=f_compute_chisqr(df_full)\n",
    "t2=time.time()\n",
    "print(\"Time to compute chi-sqr\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chi_sqr1</th>\n",
       "      <th>chi_sqr2</th>\n",
       "      <th>chi_sqr3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.006000e+03</td>\n",
       "      <td>3006.000000</td>\n",
       "      <td>3.006000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.286650e+05</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>1.028873e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.030332e+07</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.568004e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.836108e+01</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>1.918057e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.137253e+01</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>6.004830e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.262163e+01</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>8.774514e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.378358e+01</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>1.216195e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.655201e+09</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>4.685819e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           chi_sqr1     chi_sqr2      chi_sqr3\n",
       "count  3.006000e+03  3006.000000  3.006000e+03\n",
       "mean   6.286650e+05     0.000052  1.028873e+02\n",
       "std    3.030332e+07     0.000007  1.568004e+02\n",
       "min    1.836108e+01     0.000051  1.918057e-11\n",
       "25%    2.137253e+01     0.000051  6.004830e+01\n",
       "50%    2.262163e+01     0.000051  8.774514e+01\n",
       "75%    2.378358e+01     0.000052  1.216195e+02\n",
       "max    1.655201e+09     0.000374  4.685819e+03"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full[['chi_sqr1','chi_sqr2','chi_sqr3']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.000000\n",
       "1       0.000000\n",
       "2       0.000000\n",
       "3       0.000000\n",
       "4       0.000000\n",
       "5       0.000026\n",
       "6       0.000026\n",
       "7       0.000026\n",
       "8       0.000000\n",
       "9       0.000000\n",
       "10      0.000000\n",
       "11      0.000000\n",
       "12      0.000026\n",
       "13      0.000000\n",
       "14      0.000000\n",
       "15      0.000026\n",
       "16      0.000026\n",
       "17      0.500026\n",
       "18      0.000026\n",
       "19      0.000026\n",
       "20      0.000026\n",
       "21      0.000027\n",
       "22      0.000026\n",
       "23      0.000026\n",
       "24      0.000026\n",
       "25      0.000025\n",
       "26      0.500026\n",
       "27      0.000026\n",
       "28      0.000026\n",
       "29      0.000026\n",
       "          ...   \n",
       "2976    0.000026\n",
       "2977    0.000026\n",
       "2978    0.000026\n",
       "2979    0.000026\n",
       "2980    0.000026\n",
       "2981    0.000026\n",
       "2982    0.000026\n",
       "2983    0.000026\n",
       "2984    0.000026\n",
       "2985    0.000026\n",
       "2986    0.000026\n",
       "2987    0.000026\n",
       "2988    0.000026\n",
       "2989    0.000026\n",
       "2990    0.000026\n",
       "2991    0.000026\n",
       "2992    0.000026\n",
       "2993    0.000026\n",
       "2994    0.000026\n",
       "2995    0.000026\n",
       "2996    0.000025\n",
       "2997    0.000026\n",
       "2998    0.000026\n",
       "2999    0.000026\n",
       "3000    0.000026\n",
       "3001    0.000026\n",
       "3002    0.000026\n",
       "3003    0.000026\n",
       "3004    0.000026\n",
       "3005    0.000026\n",
       "Name: 0.1, Length: 3006, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.quantile(0.1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_full.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sliced=df[(df.chi_sqr1<30)&(df.chi_sqr3>88)][['epoch','step','chi_sqr1','chi_sqr2','chi_sqr3','img_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sliced.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sliced\n",
    "\n",
    "def f_plot_epochs(df,mode='epoch'):\n",
    "    \n",
    "    fig=plt.figure(figsize=(10,3))\n",
    "    # for img_type in ['val_input','val_gen','train_input','train_gen']:\n",
    "    # for img_type in ['train_gen','train_input']:\n",
    "    # for img_type in ['val_gen','val_input']:\n",
    "    for img_type in ['train_gen']:\n",
    "        df_temp=df[df.img_type==img_type]\n",
    "        \n",
    "        if mode=='epoch': x=df_temp.epoch.values\n",
    "        elif mode=='step': x=df_temp.step.values\n",
    "        print(x.shape)\n",
    "        \n",
    "        fig.add_subplot(1,3,1)\n",
    "        plt.plot(x,df_temp['chi_sqr1'].values,linestyle='-',marker='*',label=img_type)\n",
    "        plt.title('chisqr1')\n",
    "\n",
    "        fig.add_subplot(1,3,2)\n",
    "        plt.plot(x,df_temp['chi_sqr2'].values,linestyle='-',marker='*',label=img_type)\n",
    "        plt.title('chisqr2')\n",
    "\n",
    "        fig.add_subplot(1,3,3)\n",
    "        plt.plot(x,df_temp['chi_sqr3'].values,linestyle='-',marker='*',label=img_type)\n",
    "        plt.title('Deviation in histograms')\n",
    "\n",
    "    plt.xlabel(mode)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "f_plot_epochs(df_sliced,mode='step')\n",
    "f_plot_epochs(df_sliced,mode='epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Pixel images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot number of high pixel images\n",
    "# df.plot('epoch','num_large',kind='scatter')\n",
    "# df=df_full.copy()\n",
    "plt.figure()\n",
    "plt.plot(df[df.img_type=='val_gen'].step,df[df.img_type=='val_gen'].num_large,linestyle='',marker='*')\n",
    "plt.xlabel('Steps in Epochs')\n",
    "plt.ylabel('Number of large pixel images from a batch set of 128 images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.num_large>0) &(df.img_type=='val_gen')][['epoch','step','num_large','img_type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore image samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_pixel_intensity(samples2,'s2',normalize=True,mode='simple',bins=50)1\n",
    "# f_compare_pixel_intensity([samples2[20:60],samples4,['s2','s4'],normalize=normalize,log_scale=log_scale, mode=mode,bins=bins)\n",
    "# f_compute_spectrum(samples2)\n",
    "# f_compare_spectrum([samples2[20:60],samples4],['s2','s4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_widget_individual(df,img_type='val_gen',idx_range=(0,50),Fig_type='pixel',normalize=True,log_scale=True,rescale=True,mode='avg'):\n",
    "    '''\n",
    "    Module to plot pixel intensity or power spectrum for a given sample set of images\n",
    "    Options for normalization, log-scal, and rescale\n",
    "    Rescale converts image pixel values from (-1,1) to the original pixel range\n",
    "    2 Fig_type: pixel-> pixel intensity and spectrum -> power spectrum\n",
    "    '''\n",
    "    \n",
    "    start,end=idx_range[0],idx_range[1]\n",
    "    print('Index Range %s - %s'%(start,end))\n",
    "    \n",
    "    try :\n",
    "        sliced_arr=f_get_sample_epochs(df,img_type=img_type,start_epoch=start,end_epoch=end)\n",
    "        if sliced_arr.shape[0]<1:\n",
    "            print('Input indices %s %s are invalid.\\nUsing full array'%(start,end))\n",
    "            start0,end=0,'end'\n",
    "            sliced_arr=f_get_sample_epochs(df,img_type=img_type)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    ### Crop out large pixel values\n",
    "    sliced_arr=np.array([arr for arr in sliced_arr if np.max(arr)<=0.994])\n",
    "\n",
    "    if rescale: ### Converting from pixel intensity range (-1,1) to original range\n",
    "        sliced_arr=f_invtransform(sliced_arr)\n",
    "    print('Array size used',sliced_arr.shape)\n",
    "    \n",
    "    if Fig_type=='pixel':\n",
    "        f_pixel_intensity(sliced_arr,label=img_type+': {0}-{1}'.format(str(start),str(end)),normalize=normalize,log_scale=log_scale,mode=mode)\n",
    "    elif Fig_type=='spectrum':\n",
    "        f_compute_spectrum(sliced_arr,label=img_type+': {0}-{1}'.format(str(start),str(end)),log_scale=log_scale)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(f_widget_individual,df=fixed(df),img_type=fixed('val_gen'),\n",
    "                Fig_type=ToggleButtons(options=['pixel','spectrum']),mode=['avg','simple'],\n",
    "                idx_range=IntRangeSlider(value=(0,60),min=0,max=80,step=1),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View image block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/v/vpa/.conda/envs/v_py3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0bcdf6e3f2648a7af9b3596f15a8f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "f, axarr = plt.subplots(4, 4, gridspec_kw = {'wspace':0, 'hspace':0})\n",
    "\n",
    "for i, ax in enumerate(f.axes):\n",
    "    ax.grid('on', linestyle='--')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/v/vpa/.conda/envs/v_py3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3327e4c7e34abc91d187b8b0785fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'Figure' object has no attribute 'set_aspect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-7c612a01def5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mimg_arr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_get_sample_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'val_input'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m66\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mf_plot_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_arr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfig_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-7c612a01def5>\u001b[0m in \u001b[0;36mf_plot_grid\u001b[0;34m(arr, cols, fig_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_yticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_aspect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'equal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#     fig.subplots_adjust(wspace=0.00,hspace=0.000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Figure' object has no attribute 'set_aspect'"
     ]
    }
   ],
   "source": [
    "def f_plot_grid(arr,cols=16,fig_size=(15,5)):\n",
    "    ''' Plot a grid of images\n",
    "    '''\n",
    "    size=arr.shape[0]    \n",
    "    rows=int(np.ceil(size/cols))\n",
    "    print(rows,cols)\n",
    "    \n",
    "    fig,axarr=plt.subplots(rows,cols,figsize=fig_size, gridspec_kw = {'wspace':0, 'hspace':0})\n",
    "    if rows==1: axarr=np.reshape(axarr,(rows,cols))\n",
    "    if cols==1: axarr=np.reshape(axarr,(rows,cols))\n",
    "    \n",
    "    for i in range(min(rows*cols,size)):\n",
    "        row,col=int(i/cols),i%cols\n",
    "        try: \n",
    "            axarr[row,col].imshow(arr[i],origin='lower',interpolation='nearest',cmap='cool', extent = [0, 128, 0, 128])\n",
    "        # Drop axis label\n",
    "        except Exception as e:\n",
    "            print('Exception:',e)\n",
    "            pass\n",
    "        temp=plt.setp([a.get_xticklabels() for a in axarr[:-1,:].flatten()], visible=False)\n",
    "        temp=plt.setp([a.get_yticklabels() for a in axarr[:,1:].flatten()], visible=False)\n",
    "    \n",
    "#     fig.subplots_adjust(wspace=0.00,hspace=0.000)\n",
    "#     fig.tight_layout()\n",
    "\n",
    "img_arr=f_get_sample_epochs(df,'val_input',65,66)[20:50,:,:]\n",
    "f_plot_grid(img_arr,cols=6,fig_size=(10,5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_widget_compare(sample_names,sample_dict,Fig_type='pixel',rescale=True,log_scale=True,bins=25,mode='avg',normalize=True):\n",
    "    '''\n",
    "    Module to make widget plots for pixel intensity or spectrum comparison for multiple sample sets\n",
    "    '''\n",
    "    \n",
    "    ### Crop out large pixel values\n",
    "    for key in sample_names:\n",
    "        print(sample_dict[key].shape)\n",
    "        sample_dict[key]=np.array([arr for arr in sample_dict[key] if np.max(arr)<=0.994])\n",
    "        print(sample_dict[key].shape)\n",
    "    \n",
    "    img_list=[sample_dict[key] for key in sample_names]\n",
    "    label_list=list(sample_names)\n",
    "        \n",
    "    hist_range=(0,0.996)\n",
    "    \n",
    "    if rescale: \n",
    "        for count,img in enumerate(img_list):\n",
    "            img_list[count]=f_invtransform(img)\n",
    "        hist_range=(0,2000)\n",
    "    \n",
    "    assert Fig_type in ['pixel','spectrum'],\"Invalid mode %s\"%(mode)\n",
    "    \n",
    "    if Fig_type=='pixel':\n",
    "        f_compare_pixel_intensity(img_lst=img_list,label_lst=label_list,normalize=normalize,log_scale=log_scale, mode=mode,bins=bins,hist_range=hist_range)\n",
    "    elif Fig_type=='spectrum':\n",
    "        f_compare_spectrum(img_lst=img_list,label_lst=label_list,log_scale=log_scale)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare different epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_list,labels_list=f_get_sample_epochs(df,'val_gen',10)\n",
    "\n",
    "img_list,labels_list=[],[]\n",
    "# for epoch_range in [(20,25),(45,50),(55,60),(90,100),(150,160)]:\n",
    "for epoch_range in [(i,i+2) for i in range(60,75,2)]:\n",
    "# for epoch_range in [(i,i+5) for i in range(0,200,5)]:\n",
    "    start,end=epoch_range[0],epoch_range[1]\n",
    "    img_list.append(f_get_sample_epochs(df,'val_gen',start,end))\n",
    "    labels_list.append('%s:%s'%(str(start),str(end)))\n",
    "\n",
    "dict_samples=dict.fromkeys(labels_list)\n",
    "for key,val in zip(labels_list,img_list): dict_samples[key]=val\n",
    "\n",
    "### Compare with input\n",
    "dict_samples['val input']=f_get_sample_epochs(df,img_type='val_input',start_epoch=0,end_epoch=20)\n",
    "interact_manual(f_widget_compare,sample_dict=fixed(dict_samples),\n",
    "                sample_names=SelectMultiple(options=dict_samples.keys()),\n",
    "                Fig_type=ToggleButtons(options=['pixel','spectrum']),bins=IntText(value=50),mode=['avg','simple'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare image types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Available options : keys=['train_gen','train_input','val_gen','val_input']\n",
    "# start,end=70,75\n",
    "start,end=75,80\n",
    "start,end=50,55\n",
    "samples1=f_get_sample_epochs(df,'val_gen',start,end)\n",
    "samples2=f_get_sample_epochs(df,'val_input')\n",
    "samples3=f_get_sample_epochs(df,'train_gen',start,end)\n",
    "samples4=f_get_sample_epochs(df,'train_input')\n",
    "\n",
    "print(np.max(samples1))\n",
    "\n",
    "dict_samples={'s1':samples1, 's2': samples2, 's3': samples3, 's4':samples4}\n",
    "interact_manual(f_widget_compare,sample_dict=fixed(dict_samples),\n",
    "                sample_names=SelectMultiple(options=dict_samples.keys()),\n",
    "                Fig_type=ToggleButtons(options=['pixel','spectrum']),bins=IntText(value=50),mode=['avg','simple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_py3",
   "language": "python",
   "name": "v_jpt_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

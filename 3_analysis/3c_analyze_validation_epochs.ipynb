{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from output files\n",
    "### Analyze the output from a single LBANN run\n",
    "March 9, 2020 \\\n",
    "April 6, 2020 : to store files in order of epochs \\\n",
    "April 21, 2020: added jupyter widgets to compare pixel intensity plots \\\n",
    "May 8, 2020: using all images for a given batch \\\n",
    "May 29, 2020: Modified for new update of LBANN. File names of images changed, so new extraction code. Also added code for computing chi-squared. \\\n",
    "June 17, 2020: Removed train_inp, train_gen and val_inp to reduce memory overhead. From now on, the code only analyzes val_gen \\\n",
    "June 26, 2020: Added gathering of steps and new chi-square quantities.\\\n",
    "July 1, 2020: Switched back to storing mainly train_gen with large steps (10 steps saved for 256 batchsize)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import subprocess as sp\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import itertools\n",
    "import time\n",
    "from scipy import fftpack\n",
    "# from ipywidgets import interact, interact_manual,fixed, SelectMultiple, IntText, IntSlider, FloatSlider,SelectionSlider,BoundedIntText\n",
    "from ipywidgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook modules_image_analysis.ipynb to script\n",
      "[NbConvertApp] Writing 17167 bytes to modules_image_analysis.py\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/repositories/lbann_cosmogan/3_analysis')\n",
    "from modules_image_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transformation functions for image pixel values\n",
    "def f_transform(x):\n",
    "    return 2.*x/(x + 4. + 1e-8) - 1.\n",
    "\n",
    "def f_invtransform(s):\n",
    "    return 4.*(1. + s)/(1. - s + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Other transformatino functinos\n",
    "# ### Transformation functions for image pixel values\n",
    "\n",
    "# def f_transform_new(x):\n",
    "#     if x<=50:\n",
    "#         a=0.03; b=-1.0\n",
    "#         return a*x+b\n",
    "#     elif x>50: \n",
    "#         a=0.5/np.log(300)\n",
    "#         b=0.5-a*np.log(50)\n",
    "#         return a*np.log(x)+b\n",
    "\n",
    "# def f_invtransform_new(y):\n",
    "#     if y<=0.5:\n",
    "#         a=0.03;b=-1.0\n",
    "#         return (y-b)/a\n",
    "#     elif y>0.5: \n",
    "#         a=0.5/np.log(300)\n",
    "#         b=0.5-a*np.log(50)\n",
    "#         return np.exp((y-b)/a)\n",
    "    \n",
    "\n",
    "# def f_transform(x):\n",
    "#     return np.vectorize(f_transform_new)(x)\n",
    "\n",
    "# def f_invtransform(s):\n",
    "#     return np.vectorize(f_invtransform_new)(s)\n",
    "\n",
    "# f_transform_new(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules for Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_get_files_df_sorted():\n",
    "    '''\n",
    "    Module to create Dataframe with filenames for each epoch and step\n",
    "    Sorts by step and epoch\n",
    "    '''\n",
    "    \n",
    "    ## Get images files and .npy arrays for each image in dump_outs folder\n",
    "    t1=time.time()\n",
    "    files_dict={}\n",
    "#     keys=['train_gen','train_input','val_gen','val_input']\n",
    "#     file_strg_lst=['model0-training*-gen_img*-output0.npy','model0-training*-inp_img*-output0.npy','model0-validation*-gen_img*-output0.npy','model0-validation*-inp_img*-output0.npy']\n",
    "#     file_strg_lst=['sgd.training*_gen_img*_output0.npy','sgd.training*_inp_img*_output0.npy','sgd.validation*_gen_img*_output0.npy','sgd.validation*_inp_img*_output0.npy']\n",
    "\n",
    "#     keys=['val_gen']\n",
    "#     file_strg_lst=['sgd.validation*_gen_img*_output0.npy']\n",
    "    keys=['train_gen']\n",
    "    file_strg_lst=['sgd.training*_gen_img*_output0.npy']\n",
    "    \n",
    "    for key,file_strg in zip(keys,file_strg_lst):\n",
    "        files_dict[key]=np.array(glob.glob(main_dir+file_strg))\n",
    "        if files_dict[key].shape[0]>1000 : \n",
    "            print('Warning the number of files is very large. Possibility of memory overload')\n",
    "    \n",
    "    df_files=pd.DataFrame([])\n",
    "    dict1={}\n",
    "    t1=time.time()\n",
    "    ### First get sorted Dataframe with file names\n",
    "    for key in keys:\n",
    "        files_arr=files_dict[key]  # Get array of files\n",
    "        print(key,len(files_arr))\n",
    "        for fname in files_arr:\n",
    "            ### Extract the Epoch number and step number from the file name\n",
    "            dict1['img_type']=key\n",
    "            dict1['epoch']=np.int32(fname.split('epoch')[-1].split('.')[1])\n",
    "            dict1['step']=np.int64(fname.split('step')[-1].split('.')[1].split('_')[0])\n",
    "            dict1['fname']=fname\n",
    "            \n",
    "            df_files=df_files.append(dict1,ignore_index=True)\n",
    "    ## Sort values\n",
    "    df_files=df_files.sort_values(by=['img_type','epoch','step']).reset_index(drop=True)\n",
    "    # df_files\n",
    "    t2=time.time()\n",
    "    print(\"Time for Sorting\",t2-t1)\n",
    "    \n",
    "    return df_files\n",
    "\n",
    "\n",
    "def f_filter_epoch(df_input,num_sliced=1):\n",
    "    '''\n",
    "    Get just equally spaced steps for each epoch\n",
    "    '''\n",
    "    print('Extracting %s steps of each epoch'%(num_sliced))\n",
    "    df_output=pd.DataFrame([])\n",
    "#     for key in ['train_gen','train_input','val_gen','val_input']: \n",
    "    for key in ['train_gen']: \n",
    "        ### For each type of images, get list of epochs\n",
    "        df1=df_input[df_input.img_type==key]\n",
    "        epochs=np.unique(df1.epoch.values).astype(int)\n",
    "\n",
    "        for epoch in epochs:### Extract the last few steps in each epoch\n",
    "            arr_step=df1[df1.epoch==epoch].step.values   ## Get all steps\n",
    "            idxs=np.round(np.linspace(0,len(arr_step)-1,num_sliced).astype(int)) ## Get indices with equal spacing \n",
    "            df2=df1[df1.step.isin(arr_step[idxs])]        ## Get dataframe with these steps\n",
    "            df_output=df_output.append(df2)  \n",
    "    \n",
    "    return df_output.reset_index(drop=True)\n",
    "\n",
    "def f_get_images_df(df_files):\n",
    "    '''\n",
    "    Read dataframe with file names, read files and create new dataframe with images as numpy arrays\n",
    "    Also computes number of images with intensity beyond a cutoff\n",
    "    '''\n",
    "    \n",
    "    def f_row(df_row):\n",
    "        '''\n",
    "        Extract image\n",
    "        '''\n",
    "        fname,key=df_row.fname,df_row.img_type\n",
    "        a1=np.load(fname)\n",
    "        if key.endswith('input'): \n",
    "            size=np.int(np.sqrt(a1.shape[-1])) ### Extract size of images (=128)\n",
    "            batch_size=a1.shape[0] ### Number of batches\n",
    "            samples=a1.reshape(batch_size,size,size)\n",
    "        elif key.endswith('gen') : samples=a1[:,0,:,:]\n",
    "        else : raise SystemError\n",
    "\n",
    "        return samples\n",
    "    \n",
    "    def f_high_pixel(df_row,cutoff=0.9966):\n",
    "        '''\n",
    "        Get number of images with a pixel about max cut-off value\n",
    "        '''\n",
    "        max_arr=np.amax(df_row.images,axis=(1,2))\n",
    "        num_large=max_arr[max_arr>cutoff].shape[0]\n",
    "\n",
    "        return num_large\n",
    "    \n",
    "    t1=time.time()\n",
    "    ##### Create new Dataframe with sorted images\n",
    "    df=df_files.copy()\n",
    "    df['images']=df.apply(lambda row: f_row(row), axis=1)\n",
    "    t2=time.time()\n",
    "    print(\"Time for Reading images\",t2-t1)\n",
    "    \n",
    "    ### Store the number of images with large pixel value\n",
    "    cutoff=0.9966\n",
    "    df['num_large']=df.apply(lambda row: f_high_pixel(row,cutoff), axis=1)\n",
    "    \n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_get_sample_epochs(df,img_type,start_epoch=None,end_epoch=None):\n",
    "    '''\n",
    "    Module to extract images for a range of epochs given a dataframe\n",
    "    '''\n",
    "    if start_epoch==None and end_epoch==None:\n",
    "        max_epoch=np.int(np.max(df.epoch.values))\n",
    "#         print(max_epoch)\n",
    "        start_epoch=0; end_epoch=max_epoch\n",
    "#     if end_epoch==None: end_epoch=start_epoch+1\n",
    "    \n",
    "    arr=df[(df.epoch>=start_epoch) & (df.epoch<=end_epoch) & (df.img_type==img_type)].images.values\n",
    "    arr=np.vstack(arr)\n",
    "    \n",
    "    return arr\n",
    "\n",
    "\n",
    "def f_get_step(df,img_type,epoch,step):\n",
    "    '''\n",
    "    Module to extract images for a specific step and epoch\n",
    "    '''\n",
    "    \n",
    "    arr=df[(df.epoch==epoch) & (df.step==step) & (df.img_type==img_type)].images.values\n",
    "    arr=np.vstack(arr)\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def f_get_step_group(df,img_type,step_list):\n",
    "    '''\n",
    "    Module to extract images for a range of epochs given a dataframe\n",
    "    '''\n",
    "    arr=df[(df.step.isin(step_list)) & (df.img_type==img_type)].images.values\n",
    "    arr=np.vstack(arr)\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract image data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/20200701_070005_batchsize_256//dump_outs/trainer0/model0/\n"
     ]
    }
   ],
   "source": [
    "# fldr_name='20200529_111342_seed3273_80epochs'\n",
    "# fldr_name='20200626_075510_batchsize_256/'\n",
    "# fldr_name='20200701_065330_batchsize_512/'\n",
    "fldr_name='20200701_070005_batchsize_256/'\n",
    "\n",
    "main_dir='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/{0}/dump_outs/trainer0/model0/'.format(fldr_name)\n",
    "print(main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "### Extract validation data\n",
    "fname='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/raw_data/dataset_2_smoothing_200k/norm_1_train_val.npy'\n",
    "s_val=np.load(fname,mmap_mode='r')[:8000][:,0,:,:]\n",
    "print(s_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_gen 595\n",
      "Time for Sorting 1.9380252361297607\n",
      "Extracting 10 steps of each epoch\n",
      "Time for Reading images 129.99307680130005\n",
      "(595, 6)\n"
     ]
    }
   ],
   "source": [
    "### Get dataframe with file names, sorted by epoch and step\n",
    "df_files=f_get_files_df_sorted()\n",
    "### Slice out rows to keep only the last few steps for each epoch.\n",
    "df_files=f_filter_epoch(df_files,num_sliced=10)\n",
    "\n",
    "#############################################################\n",
    "### Read images one by one into a numpy array and create a new DataFrame\n",
    "df_full=f_get_images_df(df_files)\n",
    "print(df_full.shape)\n",
    "# ### Filter to keep just one step per epoch\n",
    "# df_full=f_filter_epoch(df_full,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_files.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_compute_chisqr(df,s_input):\n",
    "    ''' Compute chi-sqr values of pixel intensity histogram and spectrum for each row\n",
    "    Uses the module f_pixel_intensity to compute histograms and f_compute_spectrum for spectrum\n",
    "    '''\n",
    "    \n",
    "    def f_chisqr(df_row,val_hist,val_err,val_spec,val_spec_err,bins,transform):\n",
    "        ''' Compute chi-sqr of rows wrt to input data'''\n",
    "        \n",
    "        val_dr=val_hist.copy()\n",
    "        val_dr[val_dr<=0.]=1.0    ### Avoiding division by zero for zero bins\n",
    "        \n",
    "        ### Get all images in a batch\n",
    "        sample=df_row.images if not transform else f_invtransform(df_row.images)\n",
    "\n",
    "        ### Compute pixel histogram for row   ### !!Both pixel histograms MUST have same bins and normalization!\n",
    "        gen_hist,gen_err=f_pixel_intensity(sample,plot=False,normalize=True,bins=bins,mode='avg')\n",
    "        spec,spec_err=f_compute_spectrum(sample,plot=False)\n",
    "\n",
    "        ### Compute chi-sqr\n",
    "        ### Used in keras code : np.sum(np.divide(np.power(valhist - samphist, 2.0), valhist))\n",
    "        ###  chi_sqr :: sum((Obs-Val)^2/(Val))\n",
    "        sq_diff=(gen_hist-val_hist)**2        \n",
    "        chi_sqr_list=[]\n",
    "        \n",
    "        for count,(start,end) in enumerate(zip([0,22,38,0],[22,38,None,None])):  # 4 lists : small, medium, large pixel values and full \n",
    "            chi_sqr_list.append(np.sum(np.divide(sq_diff[start:end],val_dr[start:end])))\n",
    "        \n",
    "        idx=None  # Choosing the number of histograms to use. Eg : -5 to skip last 5 bins\n",
    "        \n",
    "        chi_sqr_list.append(np.sum(np.divide(sq_diff[:idx],1.0))) ## chi-sqr without denominator division\n",
    "        chi_sqr_list.append(np.sum(gen_err[:idx])/np.sum(val_err[:idx])) ## measures total spread in histograms wrt to input data\n",
    "        \n",
    "        ### computing the spectral loss chi-square\n",
    "        chi_sqr_list.append(np.sum((val_spec[:50]-spec[:50])**2/(spec[:50]**2)))\n",
    "        \n",
    "#         chi_sqr1=np.sum(np.divide(np.power(gen_hist[:idx] - val_hist[:idx], 2.0), val_dr[:idx]))\n",
    "#         chi_sqr2=np.sum(np.divide(np.power(gen_hist[:idx] - val_hist[:idx], 2.0), 1.0))\n",
    "#         chi_sqr3=np.sum(gen_err[:idx])/np.sum(val_err[:idx])  ## measures total spread in histograms wrt to input data\n",
    "        \n",
    "        return chi_sqr_list\n",
    "    \n",
    "    ########################\n",
    "    ###### Code starts ########\n",
    "    transform=False  # If true, it computes histogram in the orignal scale of pixels ie. 0-2000 \n",
    "    \n",
    "    ## Get bins for histograms\n",
    "    bins=np.concatenate([np.array([-0.5]),np.arange(0.5,20.5,1),np.arange(20.5,100.5,5),np.arange(100.5,1000.5,50),np.array([2000])]) #bin edges to use\n",
    "    if not transform: bins=f_transform(bins)   ### scale to (-1,1)\n",
    "#     bins=100\n",
    "#     print(bins)\n",
    "    \n",
    "    ### Get pixel histogram of all input data\n",
    "    val_hist,val_err=f_pixel_intensity(s_input,plot=False,normalize=True,bins=bins,mode='avg')    \n",
    "    ### Computing spectrum ###\n",
    "    val_spec,val_spec_err=f_compute_spectrum(s_input,plot=False)\n",
    "    del s_input\n",
    "\n",
    "\n",
    "    ### Get chi-sqr for each row (step-epoch) for generated data\n",
    "    chi_sqrs=df.apply(lambda row: f_chisqr(row,val_hist=val_hist,val_err=val_err,val_spec=val_spec,val_spec_err=val_spec_err,bins=bins,transform=transform), axis=1).values\n",
    "    chi_vals=np.array(list(zip(*chi_sqrs)))  ## transposing list of list\n",
    "        \n",
    "    chi_sqr_keys=['chi_sqr1a','chi_sqr1b','chi_sqr1c','chi_sqr1d','chi_sqr2','chi_img_var','chi_spec']\n",
    "    for key,chi_val in zip(chi_sqr_keys,chi_vals):\n",
    "        df[key]=chi_val\n",
    "    \n",
    "    return df\n",
    "\n",
    "def f_get_best_chisqr_models(df):\n",
    "    \n",
    "    chi_sqr_keys=['chi_sqr1a','chi_sqr1b','chi_sqr1c','chi_sqr1d','chi_sqr2','chi_img_var','chi_spec']\n",
    "    q_dict=dict(df.quantile(q=0.15,axis=0)[chi_sqr_keys])\n",
    "    print(q_dict)\n",
    "    \n",
    "    df_sliced=df.query('chi_sqr1d < {0} & chi_spec < {1}'.format(q_dict['chi_sqr1d'],q_dict['chi_spec']))[['epoch','step','img_type','num_large']+chi_sqr_keys]\n",
    "    \n",
    "    return df_sliced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute chi-sqr 333.44393014907837\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "# df1=f_compute_chisqr(df_full.loc[[0,1,2,3]],s_val) # Test on small df\n",
    "df_full=f_compute_chisqr(df_full,s_val)\n",
    "t2=time.time()\n",
    "print(\"Time to compute chi-sqr\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_full.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chi_sqr1a': 0.004165654180712152, 'chi_sqr1b': 0.0009722815419098029, 'chi_sqr1c': 0.0029642233830704237, 'chi_sqr1d': 0.014687615357179827, 'chi_sqr2': 0.001216211764210109, 'chi_img_var': 5.281575881818259, 'chi_spec': 0.1965580079895816}\n",
      "(14, 11)\n"
     ]
    }
   ],
   "source": [
    "df_sliced=f_get_best_chisqr_models(df_full)\n",
    "print(df_sliced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full.sort_values(by=['chi_sqr1d'])[['epoch','chi_sqr1a']].head(20)\n",
    "# Get row with min chi-sqr\n",
    "# df.loc[df.chi_sqr1.idxmin(axis=1)][['epoch','step','chi_sqr1','chi_sqr2','chi_sqr3','img_type']]\n",
    "# chi_sqr_keys=['chi_sqr1a','chi_sqr1b','chi_sqr1c','chi_sqr1d','chi_sqr2','chi_img_var','chi_spec']\n",
    "# df_full[chi_sqr_keys].describe()\n",
    "# df_full[chi_sqr_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>img_type</th>\n",
       "      <th>num_large</th>\n",
       "      <th>chi_sqr1a</th>\n",
       "      <th>chi_sqr1b</th>\n",
       "      <th>chi_sqr1c</th>\n",
       "      <th>chi_sqr1d</th>\n",
       "      <th>chi_sqr2</th>\n",
       "      <th>chi_img_var</th>\n",
       "      <th>chi_spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>27.0</td>\n",
       "      <td>21680.0</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003578</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.010099</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>6.858960</td>\n",
       "      <td>0.173512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>28.0</td>\n",
       "      <td>22480.0</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>0.011101</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>6.343215</td>\n",
       "      <td>0.124262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>33.0</td>\n",
       "      <td>26800.0</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.010188</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>5.502300</td>\n",
       "      <td>0.142282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>38.0</td>\n",
       "      <td>30880.0</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>6.129897</td>\n",
       "      <td>0.177378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>41.0</td>\n",
       "      <td>32960.0</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.007817</td>\n",
       "      <td>0.009420</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>6.382794</td>\n",
       "      <td>0.123737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>43.0</td>\n",
       "      <td>34400.0</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007232</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>0.011581</td>\n",
       "      <td>0.006226</td>\n",
       "      <td>5.345629</td>\n",
       "      <td>0.093194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>45.0</td>\n",
       "      <td>35840.0</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011664</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>6.300545</td>\n",
       "      <td>0.165678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>45.0</td>\n",
       "      <td>35920.0</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>0.014354</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>5.267575</td>\n",
       "      <td>0.170104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>46.0</td>\n",
       "      <td>36640.0</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007796</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.009483</td>\n",
       "      <td>0.003414</td>\n",
       "      <td>5.196993</td>\n",
       "      <td>0.169930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>48.0</td>\n",
       "      <td>38160.0</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.002110</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>5.263557</td>\n",
       "      <td>0.139262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>49.0</td>\n",
       "      <td>39440.0</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011246</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.013545</td>\n",
       "      <td>0.009633</td>\n",
       "      <td>5.300782</td>\n",
       "      <td>0.143665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>55.0</td>\n",
       "      <td>43920.0</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.013805</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>5.597591</td>\n",
       "      <td>0.137306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>56.0</td>\n",
       "      <td>44560.0</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007613</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.010810</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>6.858462</td>\n",
       "      <td>0.157118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>59.0</td>\n",
       "      <td>47120.0</td>\n",
       "      <td>train_gen</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.006311</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>6.095454</td>\n",
       "      <td>0.191994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch     step   img_type  num_large  chi_sqr1a  chi_sqr1b  chi_sqr1c  \\\n",
       "271   27.0  21680.0  train_gen          0   0.003578   0.001313   0.005208   \n",
       "281   28.0  22480.0  train_gen          0   0.004571   0.001058   0.005472   \n",
       "335   33.0  26800.0  train_gen          0   0.005513   0.001703   0.002973   \n",
       "386   38.0  30880.0  train_gen          0   0.003334   0.000577   0.005323   \n",
       "412   41.0  32960.0  train_gen          0   0.000633   0.000970   0.007817   \n",
       "430   43.0  34400.0  train_gen          0   0.007232   0.000774   0.003575   \n",
       "448   45.0  35840.0  train_gen          0   0.011664   0.000212   0.000615   \n",
       "449   45.0  35920.0  train_gen          0   0.005464   0.005357   0.003534   \n",
       "458   46.0  36640.0  train_gen          0   0.007796   0.000792   0.000896   \n",
       "477   48.0  38160.0  train_gen          0   0.003091   0.001198   0.002110   \n",
       "493   49.0  39440.0  train_gen          0   0.011246   0.000686   0.001612   \n",
       "549   55.0  43920.0  train_gen          0   0.012025   0.000870   0.000910   \n",
       "557   56.0  44560.0  train_gen          0   0.007613   0.002285   0.000912   \n",
       "589   59.0  47120.0  train_gen          0   0.004565   0.000814   0.000932   \n",
       "\n",
       "     chi_sqr1d  chi_sqr2  chi_img_var  chi_spec  \n",
       "271   0.010099  0.001956     6.858960  0.173512  \n",
       "281   0.011101  0.002287     6.343215  0.124262  \n",
       "335   0.010188  0.004381     5.502300  0.142282  \n",
       "386   0.009234  0.002177     6.129897  0.177378  \n",
       "412   0.009420  0.000231     6.382794  0.123737  \n",
       "430   0.011581  0.006226     5.345629  0.093194  \n",
       "448   0.012492  0.005192     6.300545  0.165678  \n",
       "449   0.014354  0.002942     5.267575  0.170104  \n",
       "458   0.009483  0.003414     5.196993  0.169930  \n",
       "477   0.006399  0.001883     5.263557  0.139262  \n",
       "493   0.013545  0.009633     5.300782  0.143665  \n",
       "549   0.013805  0.007854     5.597591  0.137306  \n",
       "557   0.010810  0.004346     6.858462  0.157118  \n",
       "589   0.006311  0.002798     6.095454  0.191994  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d2fa81de374cddb9c80faa7156f91d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2ab13887bc88>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Plot chi-sqr values\n",
    "df_sliced.plot(x=\"step\", y=[\"chi_sqr1d\", \"chi_img_var\", \"chi_spec\"],style='.',marker='*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Pixel images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot number of high pixel images\n",
    "plt.figure()\n",
    "plt.plot(df[df.img_type=='val_gen'].epoch,df[df.img_type=='val_gen'].num_large,linestyle='',marker='*')\n",
    "plt.xlabel('Steps in Epochs')\n",
    "plt.ylabel('Number of large pixel images from a batch set of 128 images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.num_large>0) &(df.img_type=='val_gen')][['epoch','step','num_large']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_widget_compare(sample_names,sample_dict,Fig_type='pixel',rescale=True,log_scale=True,bins=25,mode='avg',normalize=True,bkgnd=[]):\n",
    "    '''\n",
    "    Module to make widget plots for pixel intensity or spectrum comparison for multiple sample sets\n",
    "    '''\n",
    "#     ### Crop out large pixel values\n",
    "#     for key in sample_names:\n",
    "#         print(sample_dict[key].shape)\n",
    "#         sample_dict[key]=np.array([arr for arr in sample_dict[key] if np.max(arr)<=0.994])\n",
    "#         print(sample_dict[key].shape)\n",
    "    \n",
    "    img_list=[sample_dict[key] for key in sample_names]\n",
    "    label_list=list(sample_names)\n",
    "    \n",
    "    \n",
    "    bins=np.concatenate([np.array([-0.5]),np.arange(0.5,20.5,1),np.arange(20.5,100.5,5),np.arange(100.5,1000.5,50),np.array([2000])]) #bin edges to use\n",
    "    \n",
    "    if rescale: \n",
    "        for count,img in enumerate(img_list):\n",
    "            img_list[count]=f_invtransform(img)\n",
    "        if len(bkgnd): bkgnd=f_invtransform(bkgnd)\n",
    "#         hist_range=(0,2000)\n",
    "    else:\n",
    "        bins=f_transform(bins)\n",
    "#         hist_range=(-1,0.996)\n",
    "    assert Fig_type in ['pixel','spectrum'],\"Invalid mode %s\"%(mode)\n",
    "    \n",
    "    if Fig_type=='pixel':\n",
    "#         f_compare_pixel_intensity(img_lst=img_list,label_lst=label_list,normalize=normalize,log_scale=log_scale, mode=mode,bins=bins,hist_range=hist_range)\n",
    "        f_compare_pixel_intensity(img_lst=img_list,label_lst=label_list,normalize=normalize,log_scale=log_scale, mode=mode,bins=bins,hist_range=None,bkgnd_arr=bkgnd)\n",
    "\n",
    "    elif Fig_type=='spectrum':\n",
    "        f_compare_spectrum(img_lst=img_list,label_lst=label_list,log_scale=log_scale,bkgnd_arr=bkgnd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare different steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec040c7bccd413b8a72749913958547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='sample_names', options=('27:21680', '28:22480', '33:26800', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f_widget_compare(sample_names, sample_dict, Fig_type='pixel', rescale=True, log_scale=True, bins=25, mode='avg', normalize=True, bkgnd=[])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img_list,labels_list=f_get_sample_epochs(df,'train_gen',10)\n",
    "\n",
    "img_list,labels_list=[],[]\n",
    "for a,b in df_sliced.iterrows():\n",
    "    epoch,step=int(b.epoch),int(b.step)\n",
    "    img_list.append(f_get_step(df,'train_gen',epoch,step))\n",
    "    labels_list.append('%s:%s'%(str(epoch),str(step)))\n",
    "\n",
    "dict_samples=dict.fromkeys(labels_list)\n",
    "for key,val in zip(labels_list,img_list): dict_samples[key]=val\n",
    "\n",
    "dict_samples.keys()\n",
    "# ### Compare with input\n",
    "# # dict_samples['keras']=s_keras\n",
    "# dict_samples['input']=s_val\n",
    "bkgnd=[]\n",
    "bkgnd=s_val\n",
    "interact_manual(f_widget_compare,sample_dict=fixed(dict_samples),\n",
    "                sample_names=SelectMultiple(options=dict_samples.keys()),\n",
    "                Fig_type=ToggleButtons(options=['pixel','spectrum']),bins=IntText(value=50),mode=['avg','simple'],bkgnd=fixed(bkgnd))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot step groups in best epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(df_sliced.epoch.values))\n",
    "step_list=df_sliced[df_sliced.epoch==26].step.values\n",
    "print(step_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list,labels_list=[],[]\n",
    "for epoch in np.unique(df_sliced.epoch.values).astype(int):\n",
    "    step_list=df_sliced[df_sliced.epoch==epoch].step.values\n",
    "    print(epoch,step_list)\n",
    "    img_list.append(f_get_step_group(df,'train_gen',step_list))\n",
    "    labels_list.append('%s'%(str(epoch)))\n",
    "\n",
    "dict_samples=dict.fromkeys(labels_list)\n",
    "for key,val in zip(labels_list,img_list): dict_samples[key]=val\n",
    "\n",
    "dict_samples.keys()\n",
    "# # ### Compare with input\n",
    "# # # dict_samples['keras']=s_keras\n",
    "# # dict_samples['input']=s_val\n",
    "# bkgnd=[]\n",
    "bkgnd=s_val\n",
    "interact_manual(f_widget_compare,sample_dict=fixed(dict_samples),\n",
    "                sample_names=SelectMultiple(options=dict_samples.keys()),\n",
    "                Fig_type=ToggleButtons(options=['pixel','spectrum']),bins=IntText(value=50),mode=['avg','simple'],bkgnd=fixed(bkgnd))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_lst=[f_invtransform(i) for i in img_list]\n",
    "# bins=np.concatenate([np.array([-0.5]),np.arange(0.5,20.5,1),np.arange(20.5,100.5,5),np.arange(100.5,1000.5,50),np.array([2000])]) #bin edges to use\n",
    "# # bins=200\n",
    "# f_compare_pixel_intensity(img_list,labels_list,normalize=True,log_scale=True, mode='avg',bins=bins,hist_range=None)\n",
    "# f_compare_spectrum(img_list,labels_list,log_scale=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View image block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_plot_grid(arr,cols=16,fig_size=(15,5)):\n",
    "    ''' Plot a grid of images\n",
    "    '''\n",
    "    size=arr.shape[0]    \n",
    "    rows=int(np.ceil(size/cols))\n",
    "    print(rows,cols)\n",
    "    \n",
    "    fig,axarr=plt.subplots(rows,cols,figsize=fig_size, gridspec_kw = {'wspace':0, 'hspace':0})\n",
    "    if rows==1: axarr=np.reshape(axarr,(rows,cols))\n",
    "    if cols==1: axarr=np.reshape(axarr,(rows,cols))\n",
    "    \n",
    "    for i in range(min(rows*cols,size)):\n",
    "        row,col=int(i/cols),i%cols\n",
    "        try: \n",
    "            axarr[row,col].imshow(arr[i],origin='lower',interpolation='nearest',cmap='cool', extent = [0, 128, 0, 128])\n",
    "        # Drop axis label\n",
    "        except Exception as e:\n",
    "            print('Exception:',e)\n",
    "            pass\n",
    "        temp=plt.setp([a.get_xticklabels() for a in axarr[:-1,:].flatten()], visible=False)\n",
    "        temp=plt.setp([a.get_yticklabels() for a in axarr[:,1:].flatten()], visible=False)\n",
    "    \n",
    "#     fig.subplots_adjust(wspace=0.00,hspace=0.000)\n",
    "#     fig.tight_layout()\n",
    "\n",
    "f_plot_grid(img_arr,cols=6,fig_size=(10,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/20200701_054823_exagan/dump_outs/trainer0/model0/sgd.training.epoch.21.step.8480_gen_img_instance1_activation_output0.npy'\n",
    "# fname='/global/cfs/cdirs/m3363/vayyar/cosmogan_data/results_data/generate_images/20200629_145233_gen_img_exagan/dump_outs/trainer0/model0/sgd.testing.epoch.0.step.0_gen_img_instance1_activation_output0.npy'\n",
    "s_new=np.load(fname)[:,0,:,:]\n",
    "print(s_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_plot_grid(s_new[100:118],cols=6,fig_size=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_plot_grid(s_val[100:118],cols=6,fig_size=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_py3",
   "language": "python",
   "name": "v_jpt_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
